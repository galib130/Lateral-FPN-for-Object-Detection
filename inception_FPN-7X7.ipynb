{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mmcv-full\n!git clone https://github.com/OCM-7898/modified_mmdetection.git\n%cd modified_mmdetection\n!pip install -r requirements.txt\n!pip install grip\n\nimport mmdet\nmmdet.__path__","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2022-10-21T12:52:51.792140Z","iopub.execute_input":"2022-10-21T12:52:51.792885Z","iopub.status.idle":"2022-10-21T13:20:16.499348Z","shell.execute_reply.started":"2022-10-21T12:52:51.792793Z","shell.execute_reply":"2022-10-21T13:20:16.497944Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting mmcv-full\n  Downloading mmcv-full-1.6.2.tar.gz (575 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.1/575.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting addict\n  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (1.21.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (21.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (9.1.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (6.0)\nRequirement already satisfied: yapf in /opt/conda/lib/python3.7/site-packages (from mmcv-full) (0.32.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->mmcv-full) (3.0.9)\nBuilding wheels for collected packages: mmcv-full\n  Building wheel for mmcv-full (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mmcv-full: filename=mmcv_full-1.6.2-cp37-cp37m-linux_x86_64.whl size=28373754 sha256=62d1088d9676bf25ff8321e97b4c9b7c81bfed829386e4835a923497c16467a1\n  Stored in directory: /root/.cache/pip/wheels/51/0a/2c/990e1866b4c28e9a70ae3a0a304eeaf4711e85a87c647b8b79\nSuccessfully built mmcv-full\nInstalling collected packages: addict, mmcv-full\nSuccessfully installed addict-2.4.0 mmcv-full-1.6.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCloning into 'modified_mmdetection'...\nremote: Enumerating objects: 24890, done.\u001b[K\nremote: Total 24890 (delta 0), reused 0 (delta 0), pack-reused 24890\u001b[K\nReceiving objects: 100% (24890/24890), 37.85 MiB | 20.22 MiB/s, done.\nResolving deltas: 100% (17468/17468), done.\n/kaggle/working/modified_mmdetection\nObtaining mmtrack from git+https://github.com/open-mmlab/mmtracking#egg=mmtrack (from -r requirements/tests.txt (line 8))\n  Cloning https://github.com/open-mmlab/mmtracking to ./src/mmtrack\n  Running command git clone --filter=blob:none --quiet https://github.com/open-mmlab/mmtracking /kaggle/working/modified_mmdetection/src/mmtrack\n  Resolved https://github.com/open-mmlab/mmtracking to commit 35440e513f28bf9a7b5a09fb81008ff4b993249c\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from -r requirements/build.txt (line 2)) (0.29.32)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from -r requirements/build.txt (line 3)) (1.21.6)\nCollecting cityscapesscripts\n  Downloading cityscapesScripts-2.2.0-py3-none-any.whl (472 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.4/472.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting imagecorruptions\n  Downloading imagecorruptions-1.1.2-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from -r requirements/optional.txt (line 3)) (1.7.3)\nRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from -r requirements/optional.txt (line 4)) (0.0)\nCollecting timm\n  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from -r requirements/runtime.txt (line 1)) (3.5.3)\nCollecting pycocotools\n  Downloading pycocotools-2.0.5.tar.gz (24 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from -r requirements/runtime.txt (line 4)) (1.15.0)\nCollecting terminaltables\n  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: asynctest in /opt/conda/lib/python3.7/site-packages (from -r requirements/tests.txt (line 1)) (0.13.0)\nCollecting codecov\n  Downloading codecov-2.1.12-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: flake8 in /opt/conda/lib/python3.7/site-packages (from -r requirements/tests.txt (line 3)) (4.0.1)\nCollecting interrogate\n  Downloading interrogate-1.5.0-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting isort==4.3.21\n  Downloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting kwarray\n  Downloading kwarray-0.6.4-py3-none-any.whl (100 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting onnx==1.7.0\n  Downloading onnx-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (7.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hCollecting onnxruntime>=1.8.0\n  Downloading onnxruntime-1.12.1-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements/tests.txt (line 11)) (3.19.4)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from -r requirements/tests.txt (line 12)) (7.1.2)\nCollecting ubelt\n  Downloading ubelt-1.2.2-py3-none-any.whl (198 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.2/198.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xdoctest>=0.10.0\n  Downloading xdoctest-1.1.0-py3-none-any.whl (135 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: yapf in /opt/conda/lib/python3.7/site-packages (from -r requirements/tests.txt (line 15)) (0.32.0)\nRequirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.7/site-packages (from onnx==1.7.0->-r requirements/tests.txt (line 9)) (4.3.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from cityscapesscripts->-r requirements/optional.txt (line 1)) (4.64.0)\nCollecting coloredlogs\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyquaternion\n  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\nCollecting typing\n  Downloading typing-3.7.4.3.tar.gz (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from cityscapesscripts->-r requirements/optional.txt (line 1)) (1.4.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from cityscapesscripts->-r requirements/optional.txt (line 1)) (9.1.1)\nRequirement already satisfied: scikit-image>=0.15 in /opt/conda/lib/python3.7/site-packages (from imagecorruptions->-r requirements/optional.txt (line 2)) (0.19.3)\nRequirement already satisfied: opencv-python>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from imagecorruptions->-r requirements/optional.txt (line 2)) (4.5.4.60)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn->-r requirements/optional.txt (line 4)) (1.0.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm->-r requirements/optional.txt (line 5)) (0.12.0)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm->-r requirements/optional.txt (line 5)) (1.11.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm->-r requirements/optional.txt (line 5)) (6.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm->-r requirements/optional.txt (line 5)) (0.8.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements/runtime.txt (line 1)) (21.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements/runtime.txt (line 1)) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements/runtime.txt (line 1)) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements/runtime.txt (line 1)) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements/runtime.txt (line 1)) (1.4.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements/runtime.txt (line 1)) (4.33.3)\nRequirement already satisfied: requests>=2.7.9 in /opt/conda/lib/python3.7/site-packages (from codecov->-r requirements/tests.txt (line 2)) (2.28.1)\nCollecting coverage\n  Downloading coverage-6.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from flake8->-r requirements/tests.txt (line 3)) (2.4.0)\nRequirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/lib/python3.7/site-packages (from flake8->-r requirements/tests.txt (line 3)) (2.8.0)\nRequirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from flake8->-r requirements/tests.txt (line 3)) (0.6.1)\nCollecting importlib-metadata<4.3\n  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\nRequirement already satisfied: click>=7.1 in /opt/conda/lib/python3.7/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (8.0.4)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (0.8.10)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (0.4.5)\nRequirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (21.4.0)\nRequirement already satisfied: py in /opt/conda/lib/python3.7/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (1.11.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from interrogate->-r requirements/tests.txt (line 4)) (0.10.2)\nCollecting attributee\n  Downloading attributee-0.1.7.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting dotty_dict\n  Downloading dotty_dict-1.3.1-py3-none-any.whl (7.0 kB)\nCollecting lap\n  Downloading lap-0.4.0.tar.gz (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting mmcls<1.0.0,>=0.16.0\n  Downloading mmcls-0.24.0-py2.py3-none-any.whl (647 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.8/647.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting motmetrics\n  Downloading motmetrics-1.2.5-py3-none-any.whl (161 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas<=1.3.5 in /opt/conda/lib/python3.7/site-packages (from mmtrack->-r requirements/tests.txt (line 8)) (1.3.5)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from mmtrack->-r requirements/tests.txt (line 8)) (0.11.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.7/site-packages (from onnxruntime>=1.8.0->-r requirements/tests.txt (line 10)) (1.10.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.7/site-packages (from onnxruntime>=1.8.0->-r requirements/tests.txt (line 10)) (1.12)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->-r requirements/tests.txt (line 12)) (1.1.1)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->-r requirements/tests.txt (line 12)) (1.0.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->-r requirements/tests.txt (line 12)) (2.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8->-r requirements/tests.txt (line 3)) (3.8.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<=1.3.5->mmtrack->-r requirements/tests.txt (line 8)) (2022.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (2022.6.15)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.7.9->codecov->-r requirements/tests.txt (line 2)) (1.26.12)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.15->imagecorruptions->-r requirements/optional.txt (line 2)) (2.19.3)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.15->imagecorruptions->-r requirements/optional.txt (line 2)) (1.3.0)\nRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.15->imagecorruptions->-r requirements/optional.txt (line 2)) (2.5)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.15->imagecorruptions->-r requirements/optional.txt (line 2)) (2021.11.2)\nCollecting humanfriendly>=9.1\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm->-r requirements/optional.txt (line 5)) (3.7.1)\nCollecting xmltodict>=0.12.0\n  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements/optional.txt (line 4)) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->-r requirements/optional.txt (line 4)) (3.1.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.7/site-packages (from sympy->onnxruntime>=1.8.0->-r requirements/tests.txt (line 10)) (1.2.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.15->imagecorruptions->-r requirements/optional.txt (line 2)) (5.1.1)\nBuilding wheels for collected packages: pycocotools, attributee, lap, typing\n  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.5-cp37-cp37m-linux_x86_64.whl size=373763 sha256=08f8d375150256f675899909164810a1d8a9febf96a439b0d8c8752d211ebaa2\n  Stored in directory: /root/.cache/pip/wheels/85/c4/f0/7128093a134f590e4383fd60cb484960878721d98b9a515317\n  Building wheel for attributee (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for attributee: filename=attributee-0.1.7-py3-none-any.whl size=12696 sha256=69102d546ce1d611b997bbfa5fd9fefd182b289ce9ce70438f7c0db291e26bce\n  Stored in directory: /root/.cache/pip/wheels/28/2d/85/6a50232dcc3c9814e3bd623402757e1759e57eb99aed930729\n  Building wheel for lap (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1655040 sha256=ef6f5de988574c9b044d12d696138adf1ab1fcab545d43f1b0759379c9b1c933\n  Stored in directory: /root/.cache/pip/wheels/b1/0b/e3/ef9daf1b5547b56389e42c80c3100f1e6479bf5fd00fd9d6ba\n  Building wheel for typing (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26325 sha256=cdfcb6377457b115b8f5d285f683c1f7d7ba928ff07f3fca37e095de76a8a9dc\n  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\nSuccessfully built pycocotools attributee lap typing\nInstalling collected packages: lap, xmltodict, xdoctest, ubelt, typing, terminaltables, pyquaternion, onnx, isort, importlib-metadata, humanfriendly, dotty_dict, coverage, attributee, kwarray, coloredlogs, codecov, timm, pycocotools, onnxruntime, motmetrics, mmcls, interrogate, imagecorruptions, cityscapesscripts, mmtrack\n  Attempting uninstall: onnx\n    Found existing installation: onnx 1.12.0\n    Uninstalling onnx-1.12.0:\n      Successfully uninstalled onnx-1.12.0\n  Attempting uninstall: isort\n    Found existing installation: isort 5.10.1\n    Uninstalling isort-5.10.1:\n      Successfully uninstalled isort-5.10.1\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.12.0\n    Uninstalling importlib-metadata-4.12.0:\n      Successfully uninstalled importlib-metadata-4.12.0\n  Running setup.py develop for mmtrack\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nvirtualenv 20.16.3 requires importlib-metadata>=4.8.3; python_version < \"3.8\", but you have importlib-metadata 4.2.0 which is incompatible.\nmarkdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\ngym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed attributee-0.1.7 cityscapesscripts-2.2.0 codecov-2.1.12 coloredlogs-15.0.1 coverage-6.5.0 dotty_dict-1.3.1 humanfriendly-10.0 imagecorruptions-1.1.2 importlib-metadata-4.2.0 interrogate-1.5.0 isort-4.3.21 kwarray-0.6.4 lap-0.4.0 mmcls-0.24.0 mmtrack-0.14.0 motmetrics-1.2.5 onnx-1.7.0 onnxruntime-1.12.1 pycocotools-2.0.5 pyquaternion-0.9.9 terminaltables-3.1.10 timm-0.6.11 typing-3.7.4.3 ubelt-1.2.2 xdoctest-1.1.0 xmltodict-0.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting grip\n  Downloading grip-4.6.1-py3-none-any.whl (138 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m889.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: Werkzeug>=0.7 in /opt/conda/lib/python3.7/site-packages (from grip) (2.2.2)\nRequirement already satisfied: Pygments>=1.6 in /opt/conda/lib/python3.7/site-packages (from grip) (2.12.0)\nRequirement already satisfied: Flask>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from grip) (2.2.2)\nRequirement already satisfied: Markdown>=2.5.1 in /opt/conda/lib/python3.7/site-packages (from grip) (3.3.7)\nCollecting path-and-address>=2.0.1\n  Downloading path-and-address-2.0.1.zip (6.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: docopt>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from grip) (0.6.2)\nRequirement already satisfied: requests>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from grip) (2.28.1)\nRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.10.1->grip) (3.1.2)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.10.1->grip) (4.2.0)\nRequirement already satisfied: click>=8.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.10.1->grip) (8.0.4)\nRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.10.1->grip) (2.1.2)\nCollecting importlib-metadata>=3.6.0\n  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.4.1->grip) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.4.1->grip) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.4.1->grip) (2022.6.15)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.4.1->grip) (2.1.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from Werkzeug>=0.7->grip) (2.1.1)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask>=0.10.1->grip) (4.3.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6.0->Flask>=0.10.1->grip) (3.8.0)\nBuilding wheels for collected packages: path-and-address\n  Building wheel for path-and-address (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for path-and-address: filename=path_and_address-2.0.1-py3-none-any.whl size=4073 sha256=e531199fd6c21f8b2a061289421aec52df569a6b41dbfc20272bb5e3c52051cd\n  Stored in directory: /root/.cache/pip/wheels/97/ca/51/f8e74824b3054356141ac2dea86cea46efc55c02898fe11527\nSuccessfully built path-and-address\nInstalling collected packages: path-and-address, importlib-metadata, grip\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.2.0\n    Uninstalling importlib-metadata-4.2.0:\n      Successfully uninstalled importlib-metadata-4.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nibis-framework 2.1.1 requires importlib-metadata<5,>=4; python_version < \"3.8\", but you have importlib-metadata 5.0.0 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 5.0.0 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed grip-4.6.1 importlib-metadata-5.0.0 path-and-address-2.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/modified_mmdetection/mmdet']"},"metadata":{}}]},{"cell_type":"code","source":"!python setup.py develop ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-21T13:20:28.429686Z","iopub.execute_input":"2022-10-21T13:20:28.436554Z","iopub.status.idle":"2022-10-21T13:20:32.389221Z","shell.execute_reply.started":"2022-10-21T13:20:28.436469Z","shell.execute_reply":"2022-10-21T13:20:32.387993Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"running develop\n/opt/conda/lib/python3.7/site-packages/setuptools/command/easy_install.py:159: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n  EasyInstallDeprecationWarning,\n/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n  setuptools.SetuptoolsDeprecationWarning,\nrunning egg_info\ncreating mmdet.egg-info\nwriting mmdet.egg-info/PKG-INFO\nwriting dependency_links to mmdet.egg-info/dependency_links.txt\nwriting requirements to mmdet.egg-info/requires.txt\nwriting top-level names to mmdet.egg-info/top_level.txt\nwriting manifest file 'mmdet.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwarning: no files found matching 'mmdet/VERSION'\nwarning: no files found matching 'mmdet/.mim/demo/*/*'\nadding license file 'LICENSE'\nwriting manifest file 'mmdet.egg-info/SOURCES.txt'\n/opt/conda/lib/python3.7/site-packages/torch/utils/cpp_extension.py:387: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n  warnings.warn(msg.format('we could not find ninja.'))\nrunning build_ext\nCreating /opt/conda/lib/python3.7/site-packages/mmdet.egg-link (link to .)\nAdding mmdet 2.25.1 to easy-install.pth file\n\nInstalled /kaggle/working/modified_mmdetection\nProcessing dependencies for mmdet==2.25.1\nSearching for terminaltables==3.1.10\nBest match: terminaltables 3.1.10\nAdding terminaltables 3.1.10 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for six==1.15.0\nBest match: six 1.15.0\nAdding six 1.15.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for pycocotools==2.0.5\nBest match: pycocotools 2.0.5\nAdding pycocotools 2.0.5 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for numpy==1.21.6\nBest match: numpy 1.21.6\nAdding numpy 1.21.6 to easy-install.pth file\nInstalling f2py script to /opt/conda/bin\nInstalling f2py3 script to /opt/conda/bin\nInstalling f2py3.7 script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for matplotlib==3.5.3\nBest match: matplotlib 3.5.3\nAdding matplotlib 3.5.3 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for fonttools==4.33.3\nBest match: fonttools 4.33.3\nAdding fonttools 4.33.3 to easy-install.pth file\nInstalling fonttools script to /opt/conda/bin\nInstalling pyftmerge script to /opt/conda/bin\nInstalling pyftsubset script to /opt/conda/bin\nInstalling ttx script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for kiwisolver==1.4.3\nBest match: kiwisolver 1.4.3\nAdding kiwisolver 1.4.3 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for packaging==21.3\nBest match: packaging 21.3\nAdding packaging 21.3 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for python-dateutil==2.8.2\nBest match: python-dateutil 2.8.2\nAdding python-dateutil 2.8.2 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for cycler==0.11.0\nBest match: cycler 0.11.0\nAdding cycler 0.11.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for Pillow==9.1.1\nBest match: Pillow 9.1.1\nAdding Pillow 9.1.1 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for pyparsing==3.0.9\nBest match: pyparsing 3.0.9\nAdding pyparsing 3.0.9 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for typing-extensions==4.3.0\nBest match: typing-extensions 4.3.0\nAdding typing-extensions 4.3.0 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nFinished processing dependencies for mmdet==2.25.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from mmcv import Config\nfrom mmdet.apis import set_random_seed\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector, init_detector, inference_detector\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\nimport mmdet as mmdet\nprint(mmdet.__version__)\n\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())\n\nimport os\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nimport glob\nimport cv2\nimport shutil\nimport random\nimport os.path as osp\nimport json\nimport mmcv\nimport random\nimport re\nimport numpy as np\nimport pandas as pd\nimport xml.etree.ElementTree as ET\nfrom typing import Dict, List\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","metadata":{"execution":{"iopub.status.busy":"2022-10-21T13:20:35.557296Z","iopub.execute_input":"2022-10-21T13:20:35.558410Z","iopub.status.idle":"2022-10-21T13:20:38.165064Z","shell.execute_reply.started":"2022-10-21T13:20:35.558366Z","shell.execute_reply":"2022-10-21T13:20:38.164099Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"1.11.0 True\n2.25.1\n11.0\nGCC 9.4\n","output_type":"stream"}]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-21T13:20:38.169524Z","iopub.execute_input":"2022-10-21T13:20:38.171544Z","iopub.status.idle":"2022-10-21T13:20:38.180232Z","shell.execute_reply.started":"2022-10-21T13:20:38.171502Z","shell.execute_reply":"2022-10-21T13:20:38.179067Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/modified_mmdetection'"},"metadata":{}}]},{"cell_type":"code","source":"cd ..","metadata":{"execution":{"iopub.status.busy":"2022-10-21T13:20:39.260292Z","iopub.execute_input":"2022-10-21T13:20:39.260673Z","iopub.status.idle":"2022-10-21T13:20:39.268403Z","shell.execute_reply.started":"2022-10-21T13:20:39.260642Z","shell.execute_reply":"2022-10-21T13:20:39.266999Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir /kaggle/working/data\n!mkdir /kaggle/working/data/train-images\n!mkdir /kaggle/working/data/val-images\n!cp -a ../input/flowimgfixedannotations/train/train/. /kaggle/working/data/train-images\n!cp -a ../input/flowimgfixedannotations/test/test/. /kaggle/working/data/val-images\n!cp -a ../input/flowimgfixedannotations/test.json /kaggle/working\n!cp -a ../input/flowimgfixedannotations/train.json /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-10-21T13:20:40.529727Z","iopub.execute_input":"2022-10-21T13:20:40.530093Z","iopub.status.idle":"2022-10-21T13:21:06.301481Z","shell.execute_reply.started":"2022-10-21T13:20:40.530061Z","shell.execute_reply":"2022-10-21T13:21:06.300074Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/modified_mmdetection","metadata":{"execution":{"iopub.status.busy":"2022-10-21T16:31:35.369387Z","iopub.execute_input":"2022-10-21T16:31:35.369824Z","iopub.status.idle":"2022-10-21T16:31:35.377860Z","shell.execute_reply.started":"2022-10-21T16:31:35.369777Z","shell.execute_reply":"2022-10-21T16:31:35.376838Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"/kaggle/working/modified_mmdetection\n","output_type":"stream"}]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2022-10-21T16:30:22.003513Z","iopub.execute_input":"2022-10-21T16:30:22.003880Z","iopub.status.idle":"2022-10-21T16:30:22.010521Z","shell.execute_reply.started":"2022-10-21T16:30:22.003849Z","shell.execute_reply":"2022-10-21T16:30:22.009524Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/modified_mmdetection'"},"metadata":{}}]},{"cell_type":"code","source":"%%writefile configs/faster_rcnn/we_cascade_rcnn_r101_fpn.py\ndataset_type = 'CocoDataset'\nclasses = ('bottle',)\ndata_root = '/kaggle/working/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + 'train.json', # Modified\n        img_prefix=data_root + 'data/train-images/images', # Modified\n        classes=classes,# Added\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        ann_file=data_root + 'test.json', # Modified\n        img_prefix=data_root + 'data/val-images/images', # Modified\n        classes=classes, # Added\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        ann_file=data_root + 'test.json', # Modified\n        img_prefix=data_root + 'data/val-images/images', # Modified\n        classes=classes, # Added\n        pipeline=test_pipeline))\nevaluation = dict(interval=1, metric='bbox')\nmodel = dict(\n    type='CascadeRCNN',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        #num_stages=4,\n        #out_indices=(0, 1, 2, 3),\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet101')),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        #add_extra_convs = 'on_input',  \n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[.0, .0, .0, .0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='CascadeRoIHead',\n        num_stages=3,\n        stage_loss_weights=[1, 0.5, 0.25],\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n        ]),\n       \n    # model training and testing settings\n    train_cfg=dict(\n        rpn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.7,\n                neg_iou_thr=0.3,\n                min_pos_iou=0.3,\n                match_low_quality=True,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=256,\n                pos_fraction=0.5,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=False),\n            allowed_border=0,\n            pos_weight=-1,\n            debug=False),\n        rpn_proposal=dict(\n            nms_pre=2000,\n            max_per_img=2000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=[\n            dict(\n                assigner=dict(\n                    type='MaxIoUAssigner',\n                    pos_iou_thr=0.5,\n                    neg_iou_thr=0.5,\n                    min_pos_iou=0.5,\n                    match_low_quality=False,\n                    ignore_iof_thr=-1),\n                sampler=dict(\n                    type='RandomSampler',\n                    num=512,\n                    pos_fraction=0.25,\n                    neg_pos_ub=-1,\n                    add_gt_as_proposals=True),\n                mask_size=28,\n                pos_weight=-1,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='MaxIoUAssigner',\n                    pos_iou_thr=0.6,\n                    neg_iou_thr=0.6,\n                    min_pos_iou=0.6,\n                    match_low_quality=False,\n                    ignore_iof_thr=-1),\n                sampler=dict(\n                    type='RandomSampler',\n                    num=512,\n                    pos_fraction=0.25,\n                    neg_pos_ub=-1,\n                    add_gt_as_proposals=True),\n                mask_size=28,\n                pos_weight=-1,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='MaxIoUAssigner',\n                    pos_iou_thr=0.7,\n                    neg_iou_thr=0.7,\n                    min_pos_iou=0.7,\n                    match_low_quality=False,\n                    ignore_iof_thr=-1),\n                sampler=dict(\n                    type='RandomSampler',\n                    num=512,\n                    pos_fraction=0.25,\n                    neg_pos_ub=-1,\n                    add_gt_as_proposals=True),\n                mask_size=28,\n                pos_weight=-1,\n                debug=False)\n        ]),\n    test_cfg=dict(\n        rpn=dict(\n            nms_pre=1000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            score_thr=0.05,\n            nms=dict(type='nms', iou_threshold=0.5),\n            max_per_img=100,\n            mask_thr_binary=0.5)))\noptimizer = dict(type='SGD', lr=0.002, momentum=0.9, weight_decay=0.0001) # Modified\noptimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8,]) # If you changed max_epochs, it's better to change when you decrease LR too here.\ncheckpoint_config = dict(interval=10)\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        # dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\ncustom_hooks = [dict(type='NumClassCheckHook')]\n\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None  # Modified\nresume_from = None\nrunner = dict(\n    type='EpochBasedRunner', # Type of runner to use (i.e. IterBasedRunner or EpochBasedRunner)\n    max_epochs=30)\nworkflow = [('train', 1)]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-21T16:31:44.468877Z","iopub.execute_input":"2022-10-21T16:31:44.469645Z","iopub.status.idle":"2022-10-21T16:31:44.481691Z","shell.execute_reply.started":"2022-10-21T16:31:44.469602Z","shell.execute_reply":"2022-10-21T16:31:44.480487Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Overwriting configs/faster_rcnn/we_cascade_rcnn_r101_fpn.py\n","output_type":"stream"}]},{"cell_type":"code","source":"cd ../../","metadata":{"execution":{"iopub.status.busy":"2022-10-21T14:08:24.769844Z","iopub.execute_input":"2022-10-21T14:08:24.770234Z","iopub.status.idle":"2022-10-21T14:08:24.779883Z","shell.execute_reply.started":"2022-10-21T14:08:24.770200Z","shell.execute_reply":"2022-10-21T14:08:24.778247Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"/kaggle/working/modified_mmdetection\n","output_type":"stream"}]},{"cell_type":"code","source":"cd mmdet/models/necks","metadata":{"execution":{"iopub.status.busy":"2022-10-21T16:13:22.041848Z","iopub.execute_input":"2022-10-21T16:13:22.042260Z","iopub.status.idle":"2022-10-21T16:13:22.049635Z","shell.execute_reply.started":"2022-10-21T16:13:22.042227Z","shell.execute_reply":"2022-10-21T16:13:22.048394Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"/kaggle/working/modified_mmdetection/mmdet/models/necks\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile fpn_we.py\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom mmcv.cnn import ConvModule\nfrom mmcv.runner import BaseModule, auto_fp16\nimport torch\nimport logging\nimport numpy as np\n\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\n\n\nimport math\n\nfrom ..builder import NECKS\n\n\n@NECKS.register_module()\n# p2, p3 in the paper is p3, p4 for us \n# format of p2, p3 is both [bs, channels, height, width]\n\n\nclass FPN_WE(BaseModule):\n    r\"\"\"Feature Pyramid Network.\n    This is an implementation of paper `Feature Pyramid Networks for Object\n    Detection <https://arxiv.org/abs/1612.03144>`_.\n    Args:\n        in_channels (list[int]): Number of input channels per scale.\n        out_channels (int): Number of output channels (used at each scale).\n        num_outs (int): Number of output scales.\n        start_level (int): Index of the start input backbone level used to\n            build the feature pyramid. Default: 0.\n        end_level (int): Index of the end input backbone level (exclusive) to\n            build the feature pyramid. Default: -1, which means the last level.\n        add_extra_convs (bool | str): If bool, it decides whether to add conv\n            layers on top of the original feature maps. Default to False.\n            If True, it is equivalent to `add_extra_convs='on_input'`.\n            If str, it specifies the source feature map of the extra convs.\n            Only the following options are allowed\n            - 'on_input': Last feat map of neck inputs (i.e. backbone feature).\n            - 'on_lateral': Last feature map after lateral convs.\n            - 'on_output': The last output feature map after fpn convs.\n        relu_before_extra_convs (bool): Whether to apply relu before the extra\n            conv. Default: False.\n        no_norm_on_lateral (bool): Whether to apply norm on lateral.\n            Default: False.\n        conv_cfg (dict): Config dict for convolution layer. Default: None.\n        norm_cfg (dict): Config dict for normalization layer. Default: None.\n        act_cfg (dict): Config dict for activation layer in ConvModule.\n            Default: None.\n        upsample_cfg (dict): Config dict for interpolate layer.\n            Default: dict(mode='nearest').\n        init_cfg (dict or list[dict], optional): Initialization config dict.\n    Example:\n        >>> import torch\n        >>> in_channels = [2, 3, 5, 7]\n        >>> scales = [340, 170, 84, 43]\n        >>> inputs = [torch.rand(1, c, s, s)\n        ...           for c, s in zip(in_channels, scales)]\n        >>> self = FPN(in_channels, 11, len(in_channels)).eval()\n        >>> outputs = self.forward(inputs)\n        >>> for i in range(len(outputs)):\n        ...     print(f'outputs[{i}].shape = {outputs[i].shape}')\n        outputs[0].shape = torch.Size([1, 11, 340, 340])\n        outputs[1].shape = torch.Size([1, 11, 170, 170])\n        outputs[2].shape = torch.Size([1, 11, 84, 84])\n        outputs[3].shape = torch.Size([1, 11, 43, 43])\n    \"\"\"\n\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 num_outs,\n                 start_level=0,\n                 end_level=-1,\n                 add_extra_convs=False,\n                 relu_before_extra_convs=False,\n                 no_norm_on_lateral=False,\n                 conv_cfg=None,\n                 norm_cfg=None,\n                 act_cfg=None,\n                 upsample_cfg=dict(mode='nearest'),\n                 init_cfg=dict(\n                     type='Xavier', layer='Conv2d', distribution='uniform')):\n        super(FPN_WE, self).__init__(init_cfg)\n        assert isinstance(in_channels, list)\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.num_ins = len(in_channels)\n        self.num_outs = num_outs\n        self.relu_before_extra_convs = relu_before_extra_convs\n        self.no_norm_on_lateral = no_norm_on_lateral\n        self.fp16_enabled = False\n        self.upsample_cfg = upsample_cfg.copy()\n\n        if end_level == -1 or end_level == self.num_ins - 1:\n            self.backbone_end_level = self.num_ins\n            assert num_outs >= self.num_ins - start_level\n        else:\n            # if end_level is not the last level, no extra level is allowed\n            self.backbone_end_level = end_level + 1\n            assert end_level < self.num_ins\n            assert num_outs == end_level - start_level + 1\n        self.start_level = start_level\n        self.end_level = end_level\n        self.add_extra_convs = add_extra_convs\n        assert isinstance(add_extra_convs, (str, bool))\n        if isinstance(add_extra_convs, str):\n            # Extra_convs_source choices: 'on_input', 'on_lateral', 'on_output'\n            assert add_extra_convs in ('on_input', 'on_lateral', 'on_output')\n        elif add_extra_convs:  # True\n            self.add_extra_convs = 'on_input'\n\n        self.lateral_convs = nn.ModuleList()\n        self.fpn_convs = nn.ModuleList()\n\n        for i in range(self.start_level, self.backbone_end_level):\n            l_conv = ConvModule(\n                in_channels[i],\n                out_channels,\n                1,\n                conv_cfg=conv_cfg,\n                norm_cfg=norm_cfg if not self.no_norm_on_lateral else None,\n                act_cfg=act_cfg,\n                inplace=False)\n            fpn_conv = ConvModule(\n                out_channels,\n                out_channels,\n                3,\n                padding=1,\n                conv_cfg=conv_cfg,\n                norm_cfg=norm_cfg,\n                act_cfg=act_cfg,\n                inplace=False)\n\n            self.lateral_convs.append(l_conv)\n            self.fpn_convs.append(fpn_conv)\n            \n            \n        self.conv_5 = ConvModule(\n            256,\n            256,\n            kernel_size=7,\n            bias=False,)\n        self.conv_half = ConvModule(\n            256,\n            256,\n            kernel_size = 1,\n            bias = False,\n        )\n        self.conv_6 = ConvModule(\n            256,\n            256,\n            kernel_size=5,\n            bias=False,)\n        self.conv_7=ConvModule(\n            3*256,\n            256,\n            kernel_size=1,\n            bias=False,)\n\n        # add extra conv layers (e.g., RetinaNet)\n        extra_levels = num_outs - self.backbone_end_level + self.start_level\n\n        if self.add_extra_convs and extra_levels >= 1:\n            for i in range(extra_levels):\n                if i == 0 and self.add_extra_convs == 'on_input':\n                    in_channels = self.in_channels[self.backbone_end_level - 1]\n\n                else:\n                    in_channels = out_channels\n                extra_fpn_conv = ConvModule(\n                    in_channels,\n                    out_channels,\n                    3,\n                    stride=2,\n                    padding=1,\n                    conv_cfg=conv_cfg,\n                    norm_cfg=norm_cfg,\n                    act_cfg=act_cfg,\n                    inplace=False)\n                self.fpn_convs.append(extra_fpn_conv)\n\n    @auto_fp16()\n    def forward(self, inputs):\n        \"\"\"Forward function.\"\"\"\n        assert len(inputs) == len(self.in_channels)\n        # build laterals\n        laterals = [\n            lateral_conv(inputs[i + self.start_level])\n            for i, lateral_conv in enumerate(self.lateral_convs)\n        ]\n        # build top-down path\n        used_backbone_levels = len(laterals)\n\n        \n        \n        for i in range(used_backbone_levels - 1, 0, -1):\n            # In some cases, fixing `scale factor` (e.g. 2) is preferred, but\n            #  it cannot co-exist with `size` in `F.interpolate`.\n            count = 0  # OUR ADDITION\n            if 'scale_factor' in self.upsample_cfg:\n                # fix runtime error of \"+=\" inplace operation in PyTorch 1.10\n                print(\"Scale\")\n                laterals[i - 1] = laterals[i - 1] + F.interpolate(\n                laterals[i], **self.upsample_cfg)\n            else:\n                #if i == 1:\n                    #laterals[i-1] = FTT_get_p3pr(laterals[i],laterals[i + 1],256)\n\n                if i == 3:\n                    x = self.conv_half(laterals[i])\n                    y = self.conv_5(laterals[i-1])\n                    y = F.interpolate(y, size=x.shape[2:], **self.upsample_cfg)\n                    z=self.conv_6(laterals[i-1])\n                    z=F.interpolate(z, size=x.shape[2:], **self.upsample_cfg)\n                    \n                    inception = torch.cat((x,y,z),1)\n                    laterals[i]=self.conv_7(inception)\n#                     x = self.conv_half(laterals[i])\n#                     y = self.conv_5(laterals[i-1])\n#                     y = F.interpolate(y, size=x.shape[2:], **self.upsample_cfg)\n#                     laterals[i] = torch.cat((x,y),1)\n                if i == 2:\n                    x = self.conv_half(laterals[i])\n                    y = self.conv_5(laterals[i-1])\n                    y = F.interpolate(y, size=x.shape[2:], **self.upsample_cfg)\n                    z=self.conv_6(laterals[i-1])\n                    z=F.interpolate(z, size=x.shape[2:], **self.upsample_cfg)\n                    \n                    inception = torch.cat((x,y,z),1)\n                    laterals[i]=self.conv_7(inception)\n#                     x = self.conv_half(laterals[i])\n#                     y = self.conv_5(laterals[i-1])\n#                     y = F.interpolate(y, size=x.shape[2:], **self.upsample_cfg)\n#                     laterals[i] = torch.cat((x,y),1)\n                    prev_shape = laterals[i].shape[2:]\n                    laterals[i] = laterals[i] + F.interpolate(\n                    laterals[i+1], size=prev_shape, **self.upsample_cfg)\n                    \n                if i == 1:\n                    x = self.conv_half(laterals[i])\n                    y = self.conv_5(laterals[i-1])\n                    y = F.interpolate(y, size=x.shape[2:], **self.upsample_cfg)\n                    z=self.conv_6(laterals[i-1])\n                    z=F.interpolate(z, size=x.shape[2:], **self.upsample_cfg)\n                    \n                    inception = torch.cat((x,y,z),1)\n                    laterals[i]=self.conv_7(inception)\n#                     x = self.conv_half(laterals[i])\n#                     y = self.conv_5(laterals[i-1])\n#                     y = F.interpolate(y, size=x.shape[2:], **self.upsample_cfg)\n#                     laterals[i] = torch.cat((x,y),1)\n                    # for 1\n                    prev_shape = laterals[i].shape[2:]\n                    laterals[i] = laterals[i] + F.interpolate(\n                    laterals[i+1], size=prev_shape, **self.upsample_cfg)\n                    \n                    prev_shape = laterals[i - 1].shape[2:]\n                    laterals[i - 1] = laterals[i - 1] + F.interpolate(\n                    laterals[i], size=prev_shape, **self.upsample_cfg)\n                #prev_shape = laterals[i - 1].shape[2:]\n                #laterals[i - 1] = laterals[i - 1] + F.interpolate(laterals[i], size=prev_shape, **self.upsample_cfg)\n\n        \n        # build outputs\n        # part 1: from original levels\n        outs = [\n            self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)\n        ]\n        \n        # part 2: add extra levels\n        if self.num_outs > len(outs):\n            # use max pool to get more levels on top of outputs\n            # (e.g., Faster R-CNN, Mask R-CNN)\n            if not self.add_extra_convs:\n                for i in range(self.num_outs - used_backbone_levels):\n                    outs.append(F.max_pool2d(outs[-1], 1, stride=2))\n            # add conv layers on top of original feature maps (RetinaNet)\n            else:\n                if self.add_extra_convs == 'on_input':\n                    extra_source = inputs[self.backbone_end_level - 1]\n                elif self.add_extra_convs == 'on_lateral':\n                    extra_source = laterals[-1]\n                elif self.add_extra_convs == 'on_output':\n                    extra_source = outs[-1]\n                else:\n                    raise NotImplementedError\n                outs.append(self.fpn_convs[used_backbone_levels](extra_source))\n                for i in range(used_backbone_levels + 1, self.num_outs):\n                    if self.relu_before_extra_convs:\n                        outs.append(self.fpn_convs[i](F.relu(outs[-1])))\n                    else:\n                        outs.append(self.fpn_convs[i](outs[-1]))\n        \n        return tuple(outs)","metadata":{"execution":{"iopub.status.busy":"2022-10-21T14:15:17.001642Z","iopub.execute_input":"2022-10-21T14:15:17.002013Z","iopub.status.idle":"2022-10-21T14:15:17.016677Z","shell.execute_reply.started":"2022-10-21T14:15:17.001983Z","shell.execute_reply":"2022-10-21T14:15:17.015430Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Writing fpn_we.py\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/modified_mmdetection","metadata":{"execution":{"iopub.status.busy":"2022-10-21T16:31:52.464812Z","iopub.execute_input":"2022-10-21T16:31:52.465915Z","iopub.status.idle":"2022-10-21T16:31:52.472569Z","shell.execute_reply.started":"2022-10-21T16:31:52.465871Z","shell.execute_reply":"2022-10-21T16:31:52.471192Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"/kaggle/working/modified_mmdetection\n","output_type":"stream"}]},{"cell_type":"code","source":"!python tools/train.py configs/faster_rcnn/we_cascade_rcnn_r101_fpn.py","metadata":{"execution":{"iopub.status.busy":"2022-10-21T16:31:52.805126Z","iopub.execute_input":"2022-10-21T16:31:52.805517Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/working/modified_mmdetection/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n  f'Setting OMP_NUM_THREADS environment variable for each process '\n/kaggle/working/modified_mmdetection/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n  f'Setting MKL_NUM_THREADS environment variable for each process '\n2022-10-21 16:31:57,959 - mmdet - INFO - Environment info:\n------------------------------------------------------------\nsys.platform: linux\nPython: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]\nCUDA available: True\nGPU 0: Tesla P100-PCIE-16GB\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 11.0, V11.0.221\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\nPyTorch: 1.11.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 9.4\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX512\n  - CUDA Runtime 11.0\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_70,code=compute_70;-gencode;arch=compute_75,code=compute_75\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.0, CUDNN_VERSION=8.0.5, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.12.0\nOpenCV: 4.5.4\nMMCV: 1.6.2\nMMCV Compiler: GCC 9.4\nMMCV CUDA Compiler: 11.0\nMMDetection: 2.25.1+18a09bb\n------------------------------------------------------------\n\n2022-10-21 16:31:58,448 - mmdet - INFO - Distributed training: False\n2022-10-21 16:31:58,920 - mmdet - INFO - Config:\ndataset_type = 'CocoDataset'\nclasses = ('bottle', )\ndata_root = '/kaggle/working/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='CocoDataset',\n        ann_file='/kaggle/working/train.json',\n        img_prefix='/kaggle/working/data/train-images/images',\n        classes=('bottle', ),\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n        ]),\n    val=dict(\n        type='CocoDataset',\n        ann_file='/kaggle/working/test.json',\n        img_prefix='/kaggle/working/data/val-images/images',\n        classes=('bottle', ),\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='CocoDataset',\n        ann_file='/kaggle/working/test.json',\n        img_prefix='/kaggle/working/data/val-images/images',\n        classes=('bottle', ),\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nevaluation = dict(interval=1, metric='bbox')\nmodel = dict(\n    type='CascadeRCNN',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained',\n                      checkpoint='torchvision://resnet101')),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[0.0, 0.0, 0.0, 0.0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='CascadeRoIHead',\n        num_stages=3,\n        stage_loss_weights=[1, 0.5, 0.25],\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n        ]),\n    train_cfg=dict(\n        rpn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.7,\n                neg_iou_thr=0.3,\n                min_pos_iou=0.3,\n                match_low_quality=True,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=256,\n                pos_fraction=0.5,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=False),\n            allowed_border=0,\n            pos_weight=-1,\n            debug=False),\n        rpn_proposal=dict(\n            nms_pre=2000,\n            max_per_img=2000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=[\n            dict(\n                assigner=dict(\n                    type='MaxIoUAssigner',\n                    pos_iou_thr=0.5,\n                    neg_iou_thr=0.5,\n                    min_pos_iou=0.5,\n                    match_low_quality=False,\n                    ignore_iof_thr=-1),\n                sampler=dict(\n                    type='RandomSampler',\n                    num=512,\n                    pos_fraction=0.25,\n                    neg_pos_ub=-1,\n                    add_gt_as_proposals=True),\n                mask_size=28,\n                pos_weight=-1,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='MaxIoUAssigner',\n                    pos_iou_thr=0.6,\n                    neg_iou_thr=0.6,\n                    min_pos_iou=0.6,\n                    match_low_quality=False,\n                    ignore_iof_thr=-1),\n                sampler=dict(\n                    type='RandomSampler',\n                    num=512,\n                    pos_fraction=0.25,\n                    neg_pos_ub=-1,\n                    add_gt_as_proposals=True),\n                mask_size=28,\n                pos_weight=-1,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='MaxIoUAssigner',\n                    pos_iou_thr=0.7,\n                    neg_iou_thr=0.7,\n                    min_pos_iou=0.7,\n                    match_low_quality=False,\n                    ignore_iof_thr=-1),\n                sampler=dict(\n                    type='RandomSampler',\n                    num=512,\n                    pos_fraction=0.25,\n                    neg_pos_ub=-1,\n                    add_gt_as_proposals=True),\n                mask_size=28,\n                pos_weight=-1,\n                debug=False)\n        ]),\n    test_cfg=dict(\n        rpn=dict(\n            nms_pre=1000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            score_thr=0.05,\n            nms=dict(type='nms', iou_threshold=0.5),\n            max_per_img=100,\n            mask_thr_binary=0.5)))\noptimizer = dict(type='SGD', lr=0.002, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8])\ncheckpoint_config = dict(interval=10)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nrunner = dict(type='EpochBasedRunner', max_epochs=30)\nworkflow = [('train', 1)]\nwork_dir = './work_dirs/we_cascade_rcnn_r101_fpn'\nauto_resume = False\ngpu_ids = [0]\n\n2022-10-21 16:31:58,921 - mmdet - INFO - Set random seed to 1935092414, deterministic: False\n2022-10-21 16:31:59,866 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n2022-10-21 16:31:59,867 - mmcv - INFO - load model from: torchvision://resnet101\n2022-10-21 16:31:59,867 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet101\n2022-10-21 16:32:00,098 - mmcv - WARNING - The model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: fc.weight, fc.bias\n\n2022-10-21 16:32:00,148 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n2022-10-21 16:32:00,178 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n2022-10-21 16:32:00,183 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n2022-10-21 16:32:00,308 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n2022-10-21 16:32:00,435 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\nloading annotations into memory...\nDone (t=0.01s)\ncreating index...\nindex created!\n2022-10-21 16:32:02,405 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\nloading annotations into memory...\nDone (t=0.01s)\ncreating index...\nindex created!\n2022-10-21 16:32:02,425 - mmdet - INFO - Start running, host: root@0e5f73fcb64a, work_dir: /kaggle/working/modified_mmdetection/work_dirs/we_cascade_rcnn_r101_fpn\n2022-10-21 16:32:02,426 - mmdet - INFO - Hooks will be executed in the following order:\nbefore_run:\n(VERY_HIGH   ) StepLrUpdaterHook                  \n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n -------------------- \nbefore_train_epoch:\n(VERY_HIGH   ) StepLrUpdaterHook                  \n(NORMAL      ) NumClassCheckHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n -------------------- \nbefore_train_iter:\n(VERY_HIGH   ) StepLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n -------------------- \nafter_train_iter:\n(ABOVE_NORMAL) OptimizerHook                      \n(NORMAL      ) CheckpointHook                     \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n -------------------- \nafter_train_epoch:\n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n -------------------- \nbefore_val_epoch:\n(NORMAL      ) NumClassCheckHook                  \n(LOW         ) IterTimerHook                      \n(VERY_LOW    ) TextLoggerHook                     \n -------------------- \nbefore_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_epoch:\n(VERY_LOW    ) TextLoggerHook                     \n -------------------- \nafter_run:\n(VERY_LOW    ) TextLoggerHook                     \n -------------------- \n2022-10-21 16:32:02,426 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs\n2022-10-21 16:32:02,427 - mmdet - INFO - Checkpoints will be saved to /kaggle/working/modified_mmdetection/work_dirs/we_cascade_rcnn_r101_fpn by HardDiskBackend.\n2022-10-21 16:32:33,976 - mmdet - INFO - Epoch [1][50/600]\tlr: 1.978e-04, eta: 3:08:42, time: 0.631, data_time: 0.057, memory: 5826, loss_rpn_cls: 0.6801, loss_rpn_bbox: 0.0344, s0.loss_cls: 0.2477, s0.acc: 89.4121, s0.loss_bbox: 0.0135, s1.loss_cls: 0.1098, s1.acc: 98.2207, s1.loss_bbox: 0.0025, s2.loss_cls: 0.0770, s2.acc: 90.9062, s2.loss_bbox: 0.0003, loss: 1.1654\n2022-10-21 16:33:03,841 - mmdet - INFO - Epoch [1][100/600]\tlr: 3.976e-04, eta: 3:03:10, time: 0.597, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.2633, loss_rpn_bbox: 0.0293, s0.loss_cls: 0.0623, s0.acc: 99.2344, s0.loss_bbox: 0.0060, s1.loss_cls: 0.0303, s1.acc: 99.3828, s1.loss_bbox: 0.0018, s2.loss_cls: 0.0146, s2.acc: 99.4297, s2.loss_bbox: 0.0004, loss: 0.4080\n2022-10-21 16:33:32,680 - mmdet - INFO - Epoch [1][150/600]\tlr: 5.974e-04, eta: 2:58:58, time: 0.577, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0920, loss_rpn_bbox: 0.0271, s0.loss_cls: 0.0909, s0.acc: 97.6328, s0.loss_bbox: 0.0478, s1.loss_cls: 0.0289, s1.acc: 98.8359, s1.loss_bbox: 0.0144, s2.loss_cls: 0.0100, s2.acc: 99.2930, s2.loss_bbox: 0.0022, loss: 0.3133\n2022-10-21 16:34:00,779 - mmdet - INFO - Epoch [1][200/600]\tlr: 7.972e-04, eta: 2:55:32, time: 0.562, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0610, loss_rpn_bbox: 0.0247, s0.loss_cls: 0.1056, s0.acc: 96.8691, s0.loss_bbox: 0.0679, s1.loss_cls: 0.0329, s1.acc: 98.5645, s1.loss_bbox: 0.0213, s2.loss_cls: 0.0105, s2.acc: 99.2324, s2.loss_bbox: 0.0034, loss: 0.3274\n2022-10-21 16:34:28,827 - mmdet - INFO - Epoch [1][250/600]\tlr: 9.970e-04, eta: 2:53:13, time: 0.561, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0388, loss_rpn_bbox: 0.0211, s0.loss_cls: 0.1117, s0.acc: 96.3320, s0.loss_bbox: 0.0762, s1.loss_cls: 0.0369, s1.acc: 98.1699, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0113, s2.acc: 99.1191, s2.loss_bbox: 0.0039, loss: 0.3283\n2022-10-21 16:34:57,005 - mmdet - INFO - Epoch [1][300/600]\tlr: 1.197e-03, eta: 2:51:39, time: 0.564, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0291, loss_rpn_bbox: 0.0266, s0.loss_cls: 0.0909, s0.acc: 96.6836, s0.loss_bbox: 0.0718, s1.loss_cls: 0.0351, s1.acc: 98.0059, s1.loss_bbox: 0.0322, s2.loss_cls: 0.0109, s2.acc: 99.0664, s2.loss_bbox: 0.0049, loss: 0.3015\n2022-10-21 16:35:24,970 - mmdet - INFO - Epoch [1][350/600]\tlr: 1.397e-03, eta: 2:50:13, time: 0.559, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0204, loss_rpn_bbox: 0.0219, s0.loss_cls: 0.0944, s0.acc: 96.6074, s0.loss_bbox: 0.0719, s1.loss_cls: 0.0412, s1.acc: 97.2676, s1.loss_bbox: 0.0446, s2.loss_cls: 0.0142, s2.acc: 98.6328, s2.loss_bbox: 0.0099, loss: 0.3185\n2022-10-21 16:35:53,954 - mmdet - INFO - Epoch [1][400/600]\tlr: 1.596e-03, eta: 2:49:46, time: 0.580, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0257, loss_rpn_bbox: 0.0239, s0.loss_cls: 0.0894, s0.acc: 96.7383, s0.loss_bbox: 0.0671, s1.loss_cls: 0.0398, s1.acc: 97.2598, s1.loss_bbox: 0.0478, s2.loss_cls: 0.0137, s2.acc: 98.6504, s2.loss_bbox: 0.0099, loss: 0.3172\n2022-10-21 16:36:22,718 - mmdet - INFO - Epoch [1][450/600]\tlr: 1.796e-03, eta: 2:49:10, time: 0.575, data_time: 0.013, memory: 5826, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.0214, s0.loss_cls: 0.0867, s0.acc: 96.7441, s0.loss_bbox: 0.0767, s1.loss_cls: 0.0428, s1.acc: 96.7441, s1.loss_bbox: 0.0596, s2.loss_cls: 0.0162, s2.acc: 98.1562, s2.loss_bbox: 0.0147, loss: 0.3374\n2022-10-21 16:36:51,375 - mmdet - INFO - Epoch [1][500/600]\tlr: 1.996e-03, eta: 2:48:32, time: 0.573, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0198, loss_rpn_bbox: 0.0221, s0.loss_cls: 0.0972, s0.acc: 96.2656, s0.loss_bbox: 0.0925, s1.loss_cls: 0.0481, s1.acc: 96.1504, s1.loss_bbox: 0.0759, s2.loss_cls: 0.0188, s2.acc: 97.6191, s2.loss_bbox: 0.0195, loss: 0.3937\n2022-10-21 16:37:20,646 - mmdet - INFO - Epoch [1][550/600]\tlr: 2.000e-03, eta: 2:48:15, time: 0.585, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0206, s0.loss_cls: 0.0911, s0.acc: 96.3711, s0.loss_bbox: 0.0903, s1.loss_cls: 0.0476, s1.acc: 96.0820, s1.loss_bbox: 0.0701, s2.loss_cls: 0.0174, s2.acc: 97.8438, s2.loss_bbox: 0.0175, loss: 0.3780\n2022-10-21 16:37:49,541 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:37:49,542 - mmdet - INFO - Epoch [1][600/600]\tlr: 2.000e-03, eta: 2:47:45, time: 0.578, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0120, loss_rpn_bbox: 0.0196, s0.loss_cls: 0.0834, s0.acc: 96.7441, s0.loss_bbox: 0.0840, s1.loss_cls: 0.0457, s1.acc: 96.1914, s1.loss_bbox: 0.0790, s2.loss_cls: 0.0202, s2.acc: 97.0977, s2.loss_bbox: 0.0277, loss: 0.3715\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.4 task/s, elapsed: 95s, ETA:     0s2022-10-21 16:39:24,850 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.02s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=1.92s).\nAccumulating evaluation results...\nDONE (t=0.52s).\n2022-10-21 16:39:27,495 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.585\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.042\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.289\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.368\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.338\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.338\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.269\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.418\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.510\n\n2022-10-21 16:39:27,510 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:39:27,511 - mmdet - INFO - Epoch(val) [1][800]\tbbox_mAP: 0.1920, bbox_mAP_50: 0.5850, bbox_mAP_75: 0.0420, bbox_mAP_s: 0.1000, bbox_mAP_m: 0.2890, bbox_mAP_l: 0.3680, bbox_mAP_copypaste: 0.192 0.585 0.042 0.100 0.289 0.368\n2022-10-21 16:39:58,604 - mmdet - INFO - Epoch [2][50/600]\tlr: 2.000e-03, eta: 2:48:14, time: 0.622, data_time: 0.056, memory: 5826, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0216, s0.loss_cls: 0.0952, s0.acc: 96.2637, s0.loss_bbox: 0.0907, s1.loss_cls: 0.0537, s1.acc: 95.4585, s1.loss_bbox: 0.0980, s2.loss_cls: 0.0249, s2.acc: 95.9353, s2.loss_bbox: 0.0381, loss: 0.4383\n2022-10-21 16:40:27,683 - mmdet - INFO - Epoch [2][100/600]\tlr: 2.000e-03, eta: 2:47:44, time: 0.582, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0142, loss_rpn_bbox: 0.0183, s0.loss_cls: 0.0785, s0.acc: 96.8477, s0.loss_bbox: 0.0769, s1.loss_cls: 0.0454, s1.acc: 96.2461, s1.loss_bbox: 0.0781, s2.loss_cls: 0.0209, s2.acc: 96.6738, s2.loss_bbox: 0.0306, loss: 0.3629\n2022-10-21 16:40:57,007 - mmdet - INFO - Epoch [2][150/600]\tlr: 2.000e-03, eta: 2:47:21, time: 0.586, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0120, loss_rpn_bbox: 0.0192, s0.loss_cls: 0.0727, s0.acc: 97.0977, s0.loss_bbox: 0.0794, s1.loss_cls: 0.0442, s1.acc: 96.1339, s1.loss_bbox: 0.0938, s2.loss_cls: 0.0223, s2.acc: 96.0651, s2.loss_bbox: 0.0434, loss: 0.3869\n2022-10-21 16:41:26,412 - mmdet - INFO - Epoch [2][200/600]\tlr: 2.000e-03, eta: 2:46:58, time: 0.588, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0137, loss_rpn_bbox: 0.0184, s0.loss_cls: 0.0892, s0.acc: 96.3223, s0.loss_bbox: 0.0925, s1.loss_cls: 0.0502, s1.acc: 95.8408, s1.loss_bbox: 0.1007, s2.loss_cls: 0.0255, s2.acc: 95.8017, s2.loss_bbox: 0.0433, loss: 0.4334\n2022-10-21 16:41:55,586 - mmdet - INFO - Epoch [2][250/600]\tlr: 2.000e-03, eta: 2:46:30, time: 0.583, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0112, loss_rpn_bbox: 0.0183, s0.loss_cls: 0.0829, s0.acc: 96.7637, s0.loss_bbox: 0.0870, s1.loss_cls: 0.0509, s1.acc: 95.7045, s1.loss_bbox: 0.1094, s2.loss_cls: 0.0266, s2.acc: 95.2366, s2.loss_bbox: 0.0504, loss: 0.4367\n2022-10-21 16:42:24,586 - mmdet - INFO - Epoch [2][300/600]\tlr: 2.000e-03, eta: 2:45:58, time: 0.580, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0145, loss_rpn_bbox: 0.0182, s0.loss_cls: 0.0892, s0.acc: 96.4004, s0.loss_bbox: 0.0877, s1.loss_cls: 0.0531, s1.acc: 95.4395, s1.loss_bbox: 0.0978, s2.loss_cls: 0.0263, s2.acc: 95.6074, s2.loss_bbox: 0.0428, loss: 0.4296\n2022-10-21 16:42:53,564 - mmdet - INFO - Epoch [2][350/600]\tlr: 2.000e-03, eta: 2:45:27, time: 0.580, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0119, loss_rpn_bbox: 0.0192, s0.loss_cls: 0.0909, s0.acc: 96.2949, s0.loss_bbox: 0.0909, s1.loss_cls: 0.0551, s1.acc: 95.1824, s1.loss_bbox: 0.1135, s2.loss_cls: 0.0312, s2.acc: 94.2562, s2.loss_bbox: 0.0541, loss: 0.4667\n2022-10-21 16:43:22,515 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:43:22,515 - mmdet - INFO - Epoch [2][400/600]\tlr: 2.000e-03, eta: 2:44:55, time: 0.579, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0180, s0.loss_cls: 0.0772, s0.acc: 96.9258, s0.loss_bbox: 0.0831, s1.loss_cls: 0.0472, s1.acc: 95.9248, s1.loss_bbox: 0.1048, s2.loss_cls: 0.0265, s2.acc: 95.1476, s2.loss_bbox: 0.0547, loss: 0.4202\n2022-10-21 16:43:51,341 - mmdet - INFO - Epoch [2][450/600]\tlr: 2.000e-03, eta: 2:44:21, time: 0.577, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0162, s0.loss_cls: 0.0677, s0.acc: 97.3398, s0.loss_bbox: 0.0675, s1.loss_cls: 0.0418, s1.acc: 96.4435, s1.loss_bbox: 0.0956, s2.loss_cls: 0.0261, s2.acc: 94.8591, s2.loss_bbox: 0.0526, loss: 0.3748\n2022-10-21 16:44:20,074 - mmdet - INFO - Epoch [2][500/600]\tlr: 2.000e-03, eta: 2:43:47, time: 0.575, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0179, s0.loss_cls: 0.0697, s0.acc: 97.1738, s0.loss_bbox: 0.0743, s1.loss_cls: 0.0426, s1.acc: 96.3531, s1.loss_bbox: 0.1064, s2.loss_cls: 0.0275, s2.acc: 94.9343, s2.loss_bbox: 0.0639, loss: 0.4128\n2022-10-21 16:44:48,940 - mmdet - INFO - Epoch [2][550/600]\tlr: 2.000e-03, eta: 2:43:15, time: 0.577, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0109, loss_rpn_bbox: 0.0168, s0.loss_cls: 0.0748, s0.acc: 96.8438, s0.loss_bbox: 0.0807, s1.loss_cls: 0.0467, s1.acc: 95.9977, s1.loss_bbox: 0.1087, s2.loss_cls: 0.0270, s2.acc: 95.0917, s2.loss_bbox: 0.0636, loss: 0.4292\n2022-10-21 16:45:17,559 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:45:17,559 - mmdet - INFO - Epoch [2][600/600]\tlr: 2.000e-03, eta: 2:42:39, time: 0.572, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0158, s0.loss_cls: 0.0749, s0.acc: 96.9199, s0.loss_bbox: 0.0806, s1.loss_cls: 0.0467, s1.acc: 95.8262, s1.loss_bbox: 0.1059, s2.loss_cls: 0.0273, s2.acc: 94.8740, s2.loss_bbox: 0.0574, loss: 0.4174\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.4 task/s, elapsed: 96s, ETA:     0s2022-10-21 16:46:53,294 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.13s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.73s).\nAccumulating evaluation results...\nDONE (t=0.16s).\n2022-10-21 16:46:54,331 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.718\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.145\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.164\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.425\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.435\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.368\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.368\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.246\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.529\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.543\n\n2022-10-21 16:46:54,341 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:46:54,341 - mmdet - INFO - Epoch(val) [2][800]\tbbox_mAP: 0.2810, bbox_mAP_50: 0.7180, bbox_mAP_75: 0.1450, bbox_mAP_s: 0.1640, bbox_mAP_m: 0.4250, bbox_mAP_l: 0.4350, bbox_mAP_copypaste: 0.281 0.718 0.145 0.164 0.425 0.435\n2022-10-21 16:47:25,627 - mmdet - INFO - Epoch [3][50/600]\tlr: 2.000e-03, eta: 2:42:40, time: 0.625, data_time: 0.057, memory: 5826, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0155, s0.loss_cls: 0.0664, s0.acc: 97.2988, s0.loss_bbox: 0.0651, s1.loss_cls: 0.0420, s1.acc: 96.4838, s1.loss_bbox: 0.0971, s2.loss_cls: 0.0270, s2.acc: 94.8774, s2.loss_bbox: 0.0580, loss: 0.3784\n2022-10-21 16:47:54,356 - mmdet - INFO - Epoch [3][100/600]\tlr: 2.000e-03, eta: 2:42:06, time: 0.575, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.0677, s0.acc: 97.2617, s0.loss_bbox: 0.0768, s1.loss_cls: 0.0417, s1.acc: 96.4885, s1.loss_bbox: 0.1105, s2.loss_cls: 0.0270, s2.acc: 94.7031, s2.loss_bbox: 0.0702, loss: 0.4168\n2022-10-21 16:48:23,082 - mmdet - INFO - Epoch [3][150/600]\tlr: 2.000e-03, eta: 2:41:32, time: 0.575, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0131, loss_rpn_bbox: 0.0163, s0.loss_cls: 0.0708, s0.acc: 97.2441, s0.loss_bbox: 0.0753, s1.loss_cls: 0.0433, s1.acc: 96.5268, s1.loss_bbox: 0.1162, s2.loss_cls: 0.0297, s2.acc: 94.4559, s2.loss_bbox: 0.0757, loss: 0.4404\n2022-10-21 16:48:52,254 - mmdet - INFO - Epoch [3][200/600]\tlr: 2.000e-03, eta: 2:41:03, time: 0.583, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0165, s0.loss_cls: 0.0743, s0.acc: 96.9277, s0.loss_bbox: 0.0730, s1.loss_cls: 0.0441, s1.acc: 96.2479, s1.loss_bbox: 0.1149, s2.loss_cls: 0.0294, s2.acc: 94.5554, s2.loss_bbox: 0.0787, loss: 0.4386\n2022-10-21 16:49:20,852 - mmdet - INFO - Epoch [3][250/600]\tlr: 2.000e-03, eta: 2:40:28, time: 0.572, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0194, s0.loss_cls: 0.0837, s0.acc: 96.4629, s0.loss_bbox: 0.0949, s1.loss_cls: 0.0500, s1.acc: 95.6161, s1.loss_bbox: 0.1322, s2.loss_cls: 0.0308, s2.acc: 94.2458, s2.loss_bbox: 0.0758, loss: 0.4957\n2022-10-21 16:49:49,944 - mmdet - INFO - Epoch [3][300/600]\tlr: 2.000e-03, eta: 2:39:59, time: 0.582, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0164, s0.loss_cls: 0.0642, s0.acc: 97.2715, s0.loss_bbox: 0.0774, s1.loss_cls: 0.0405, s1.acc: 96.4694, s1.loss_bbox: 0.1117, s2.loss_cls: 0.0262, s2.acc: 95.1126, s2.loss_bbox: 0.0664, loss: 0.4103\n2022-10-21 16:50:18,972 - mmdet - INFO - Epoch [3][350/600]\tlr: 2.000e-03, eta: 2:39:29, time: 0.581, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0094, loss_rpn_bbox: 0.0186, s0.loss_cls: 0.0793, s0.acc: 96.7559, s0.loss_bbox: 0.0922, s1.loss_cls: 0.0450, s1.acc: 96.3063, s1.loss_bbox: 0.1303, s2.loss_cls: 0.0305, s2.acc: 94.3991, s2.loss_bbox: 0.0833, loss: 0.4886\n2022-10-21 16:50:47,238 - mmdet - INFO - Epoch [3][400/600]\tlr: 2.000e-03, eta: 2:38:52, time: 0.565, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0144, s0.loss_cls: 0.0665, s0.acc: 97.2988, s0.loss_bbox: 0.0706, s1.loss_cls: 0.0413, s1.acc: 96.6019, s1.loss_bbox: 0.1141, s2.loss_cls: 0.0287, s2.acc: 94.8634, s2.loss_bbox: 0.0814, loss: 0.4245\n2022-10-21 16:51:15,974 - mmdet - INFO - Epoch [3][450/600]\tlr: 2.000e-03, eta: 2:38:20, time: 0.575, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0129, s0.loss_cls: 0.0623, s0.acc: 97.4043, s0.loss_bbox: 0.0672, s1.loss_cls: 0.0388, s1.acc: 96.7802, s1.loss_bbox: 0.1081, s2.loss_cls: 0.0261, s2.acc: 95.5024, s2.loss_bbox: 0.0752, loss: 0.3950\n2022-10-21 16:51:44,804 - mmdet - INFO - Epoch [3][500/600]\tlr: 2.000e-03, eta: 2:37:48, time: 0.577, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0186, s0.loss_cls: 0.0708, s0.acc: 97.0918, s0.loss_bbox: 0.0839, s1.loss_cls: 0.0440, s1.acc: 96.2376, s1.loss_bbox: 0.1278, s2.loss_cls: 0.0295, s2.acc: 94.8397, s2.loss_bbox: 0.0872, loss: 0.4692\n2022-10-21 16:52:13,405 - mmdet - INFO - Epoch [3][550/600]\tlr: 2.000e-03, eta: 2:37:15, time: 0.572, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0592, s0.acc: 97.5254, s0.loss_bbox: 0.0639, s1.loss_cls: 0.0346, s1.acc: 97.1235, s1.loss_bbox: 0.1007, s2.loss_cls: 0.0245, s2.acc: 95.7015, s2.loss_bbox: 0.0717, loss: 0.3745\n2022-10-21 16:52:41,637 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:52:41,638 - mmdet - INFO - Epoch [3][600/600]\tlr: 2.000e-03, eta: 2:36:39, time: 0.565, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0150, s0.loss_cls: 0.0681, s0.acc: 97.1309, s0.loss_bbox: 0.0666, s1.loss_cls: 0.0419, s1.acc: 96.4617, s1.loss_bbox: 0.0979, s2.loss_cls: 0.0269, s2.acc: 94.7629, s2.loss_bbox: 0.0566, loss: 0.3801\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.4 task/s, elapsed: 95s, ETA:     0s2022-10-21 16:54:16,676 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=1.60s).\nAccumulating evaluation results...\nDONE (t=0.27s).\n2022-10-21 16:54:18,598 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.779\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.227\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.186\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.486\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.592\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.431\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.431\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.326\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.558\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.667\n\n2022-10-21 16:54:18,609 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:54:18,610 - mmdet - INFO - Epoch(val) [3][800]\tbbox_mAP: 0.3340, bbox_mAP_50: 0.7790, bbox_mAP_75: 0.2270, bbox_mAP_s: 0.1860, bbox_mAP_m: 0.4860, bbox_mAP_l: 0.5920, bbox_mAP_copypaste: 0.334 0.779 0.227 0.186 0.486 0.592\n2022-10-21 16:54:49,773 - mmdet - INFO - Epoch [4][50/600]\tlr: 2.000e-03, eta: 2:36:29, time: 0.623, data_time: 0.057, memory: 5826, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0141, s0.loss_cls: 0.0659, s0.acc: 97.3105, s0.loss_bbox: 0.0672, s1.loss_cls: 0.0394, s1.acc: 96.8170, s1.loss_bbox: 0.1051, s2.loss_cls: 0.0249, s2.acc: 95.5520, s2.loss_bbox: 0.0730, loss: 0.3970\n2022-10-21 16:55:18,639 - mmdet - INFO - Epoch [4][100/600]\tlr: 2.000e-03, eta: 2:35:58, time: 0.577, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0147, s0.loss_cls: 0.0674, s0.acc: 97.2324, s0.loss_bbox: 0.0685, s1.loss_cls: 0.0389, s1.acc: 96.8347, s1.loss_bbox: 0.1007, s2.loss_cls: 0.0253, s2.acc: 95.6432, s2.loss_bbox: 0.0715, loss: 0.3946\n2022-10-21 16:55:47,583 - mmdet - INFO - Epoch [4][150/600]\tlr: 2.000e-03, eta: 2:35:28, time: 0.579, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0196, s0.loss_cls: 0.0779, s0.acc: 96.8105, s0.loss_bbox: 0.0832, s1.loss_cls: 0.0483, s1.acc: 95.9431, s1.loss_bbox: 0.1249, s2.loss_cls: 0.0315, s2.acc: 94.1102, s2.loss_bbox: 0.0826, loss: 0.4778\n2022-10-21 16:56:16,531 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 16:56:16,531 - mmdet - INFO - Epoch [4][200/600]\tlr: 2.000e-03, eta: 2:34:58, time: 0.579, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0166, s0.loss_cls: 0.0688, s0.acc: 97.0176, s0.loss_bbox: 0.0810, s1.loss_cls: 0.0423, s1.acc: 96.3879, s1.loss_bbox: 0.1257, s2.loss_cls: 0.0276, s2.acc: 94.8417, s2.loss_bbox: 0.0856, loss: 0.4531\n2022-10-21 16:56:45,273 - mmdet - INFO - Epoch [4][250/600]\tlr: 2.000e-03, eta: 2:34:26, time: 0.575, data_time: 0.013, memory: 5826, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0138, s0.loss_cls: 0.0545, s0.acc: 97.6211, s0.loss_bbox: 0.0638, s1.loss_cls: 0.0344, s1.acc: 97.0299, s1.loss_bbox: 0.1135, s2.loss_cls: 0.0259, s2.acc: 95.3565, s2.loss_bbox: 0.0849, loss: 0.3947\n2022-10-21 16:57:13,987 - mmdet - INFO - Epoch [4][300/600]\tlr: 2.000e-03, eta: 2:33:55, time: 0.574, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0181, s0.loss_cls: 0.0669, s0.acc: 97.2480, s0.loss_bbox: 0.0773, s1.loss_cls: 0.0412, s1.acc: 96.4686, s1.loss_bbox: 0.1204, s2.loss_cls: 0.0269, s2.acc: 95.0146, s2.loss_bbox: 0.0822, loss: 0.4393\n2022-10-21 16:57:42,828 - mmdet - INFO - Epoch [4][350/600]\tlr: 2.000e-03, eta: 2:33:24, time: 0.577, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0162, s0.loss_cls: 0.0708, s0.acc: 97.1660, s0.loss_bbox: 0.0748, s1.loss_cls: 0.0387, s1.acc: 96.8310, s1.loss_bbox: 0.1182, s2.loss_cls: 0.0264, s2.acc: 95.4757, s2.loss_bbox: 0.0894, loss: 0.4420\n2022-10-21 16:58:11,701 - mmdet - INFO - Epoch [4][400/600]\tlr: 2.000e-03, eta: 2:32:54, time: 0.577, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0548, s0.acc: 97.6523, s0.loss_bbox: 0.0617, s1.loss_cls: 0.0344, s1.acc: 97.1505, s1.loss_bbox: 0.0988, s2.loss_cls: 0.0234, s2.acc: 95.7015, s2.loss_bbox: 0.0708, loss: 0.3623\n2022-10-21 16:58:40,593 - mmdet - INFO - Epoch [4][450/600]\tlr: 2.000e-03, eta: 2:32:24, time: 0.578, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0141, s0.loss_cls: 0.0616, s0.acc: 97.5020, s0.loss_bbox: 0.0716, s1.loss_cls: 0.0371, s1.acc: 96.9252, s1.loss_bbox: 0.1151, s2.loss_cls: 0.0257, s2.acc: 95.3747, s2.loss_bbox: 0.0807, loss: 0.4138\n2022-10-21 16:59:09,440 - mmdet - INFO - Epoch [4][500/600]\tlr: 2.000e-03, eta: 2:31:54, time: 0.577, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0515, s0.acc: 97.8691, s0.loss_bbox: 0.0558, s1.loss_cls: 0.0323, s1.acc: 97.3300, s1.loss_bbox: 0.0918, s2.loss_cls: 0.0227, s2.acc: 96.1166, s2.loss_bbox: 0.0710, loss: 0.3437\n2022-10-21 16:59:38,108 - mmdet - INFO - Epoch [4][550/600]\tlr: 2.000e-03, eta: 2:31:22, time: 0.573, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0594, s0.acc: 97.5117, s0.loss_bbox: 0.0663, s1.loss_cls: 0.0344, s1.acc: 97.1100, s1.loss_bbox: 0.1103, s2.loss_cls: 0.0247, s2.acc: 95.5801, s2.loss_bbox: 0.0787, loss: 0.3931\n2022-10-21 17:00:06,858 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:00:06,858 - mmdet - INFO - Epoch [4][600/600]\tlr: 2.000e-03, eta: 2:30:52, time: 0.575, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0140, s0.loss_cls: 0.0659, s0.acc: 97.3398, s0.loss_bbox: 0.0743, s1.loss_cls: 0.0394, s1.acc: 96.7974, s1.loss_bbox: 0.1179, s2.loss_cls: 0.0276, s2.acc: 95.0895, s2.loss_bbox: 0.0905, loss: 0.4360\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.5 task/s, elapsed: 95s, ETA:     0s2022-10-21 17:01:41,715 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.71s).\nAccumulating evaluation results...\nDONE (t=0.15s).\n2022-10-21 17:01:42,605 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.827\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.162\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.220\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.431\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.490\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.399\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.399\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.321\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.499\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.538\n\n2022-10-21 17:01:42,613 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:01:42,613 - mmdet - INFO - Epoch(val) [4][800]\tbbox_mAP: 0.3240, bbox_mAP_50: 0.8270, bbox_mAP_75: 0.1620, bbox_mAP_s: 0.2200, bbox_mAP_m: 0.4310, bbox_mAP_l: 0.4900, bbox_mAP_copypaste: 0.324 0.827 0.162 0.220 0.431 0.490\n2022-10-21 17:02:13,616 - mmdet - INFO - Epoch [5][50/600]\tlr: 2.000e-03, eta: 2:30:35, time: 0.620, data_time: 0.057, memory: 5826, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0115, s0.loss_cls: 0.0565, s0.acc: 97.6152, s0.loss_bbox: 0.0613, s1.loss_cls: 0.0346, s1.acc: 97.0783, s1.loss_bbox: 0.1005, s2.loss_cls: 0.0250, s2.acc: 95.5389, s2.loss_bbox: 0.0742, loss: 0.3678\n2022-10-21 17:02:42,380 - mmdet - INFO - Epoch [5][100/600]\tlr: 2.000e-03, eta: 2:30:04, time: 0.575, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0163, s0.loss_cls: 0.0601, s0.acc: 97.4688, s0.loss_bbox: 0.0706, s1.loss_cls: 0.0359, s1.acc: 96.9453, s1.loss_bbox: 0.1166, s2.loss_cls: 0.0251, s2.acc: 95.5830, s2.loss_bbox: 0.0904, loss: 0.4215\n2022-10-21 17:03:10,901 - mmdet - INFO - Epoch [5][150/600]\tlr: 2.000e-03, eta: 2:29:32, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0159, s0.loss_cls: 0.0666, s0.acc: 97.2617, s0.loss_bbox: 0.0762, s1.loss_cls: 0.0394, s1.acc: 96.7079, s1.loss_bbox: 0.1174, s2.loss_cls: 0.0269, s2.acc: 94.9864, s2.loss_bbox: 0.0891, loss: 0.4364\n2022-10-21 17:03:39,544 - mmdet - INFO - Epoch [5][200/600]\tlr: 2.000e-03, eta: 2:29:01, time: 0.573, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0108, s0.loss_cls: 0.0476, s0.acc: 98.0312, s0.loss_bbox: 0.0543, s1.loss_cls: 0.0299, s1.acc: 97.4232, s1.loss_bbox: 0.0982, s2.loss_cls: 0.0226, s2.acc: 96.0464, s2.loss_bbox: 0.0790, loss: 0.3469\n2022-10-21 17:04:08,185 - mmdet - INFO - Epoch [5][250/600]\tlr: 2.000e-03, eta: 2:28:29, time: 0.573, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0153, s0.loss_cls: 0.0573, s0.acc: 97.5996, s0.loss_bbox: 0.0703, s1.loss_cls: 0.0347, s1.acc: 97.1600, s1.loss_bbox: 0.1169, s2.loss_cls: 0.0246, s2.acc: 95.5631, s2.loss_bbox: 0.0891, loss: 0.4134\n2022-10-21 17:04:36,556 - mmdet - INFO - Epoch [5][300/600]\tlr: 2.000e-03, eta: 2:27:57, time: 0.567, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0156, s0.loss_cls: 0.0574, s0.acc: 97.6016, s0.loss_bbox: 0.0694, s1.loss_cls: 0.0349, s1.acc: 97.1251, s1.loss_bbox: 0.1114, s2.loss_cls: 0.0251, s2.acc: 95.5142, s2.loss_bbox: 0.0863, loss: 0.4049\n2022-10-21 17:05:05,094 - mmdet - INFO - Epoch [5][350/600]\tlr: 2.000e-03, eta: 2:27:25, time: 0.571, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.0546, s0.acc: 97.7520, s0.loss_bbox: 0.0656, s1.loss_cls: 0.0337, s1.acc: 97.1684, s1.loss_bbox: 0.1084, s2.loss_cls: 0.0254, s2.acc: 95.3488, s2.loss_bbox: 0.0837, loss: 0.3902\n2022-10-21 17:05:33,217 - mmdet - INFO - Epoch [5][400/600]\tlr: 2.000e-03, eta: 2:26:51, time: 0.562, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0116, s0.loss_cls: 0.0465, s0.acc: 98.0254, s0.loss_bbox: 0.0505, s1.loss_cls: 0.0291, s1.acc: 97.5742, s1.loss_bbox: 0.0902, s2.loss_cls: 0.0214, s2.acc: 96.3333, s2.loss_bbox: 0.0706, loss: 0.3230\n2022-10-21 17:06:01,845 - mmdet - INFO - Epoch [5][450/600]\tlr: 2.000e-03, eta: 2:26:20, time: 0.573, data_time: 0.013, memory: 5826, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0102, s0.loss_cls: 0.0468, s0.acc: 98.0371, s0.loss_bbox: 0.0490, s1.loss_cls: 0.0286, s1.acc: 97.6344, s1.loss_bbox: 0.0918, s2.loss_cls: 0.0208, s2.acc: 96.2358, s2.loss_bbox: 0.0780, loss: 0.3283\n2022-10-21 17:06:30,385 - mmdet - INFO - Epoch [5][500/600]\tlr: 2.000e-03, eta: 2:25:49, time: 0.571, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0138, s0.loss_cls: 0.0547, s0.acc: 97.7988, s0.loss_bbox: 0.0624, s1.loss_cls: 0.0319, s1.acc: 97.3950, s1.loss_bbox: 0.1030, s2.loss_cls: 0.0216, s2.acc: 96.1332, s2.loss_bbox: 0.0766, loss: 0.3693\n2022-10-21 17:06:58,741 - mmdet - INFO - Epoch [5][550/600]\tlr: 2.000e-03, eta: 2:25:17, time: 0.567, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0136, s0.loss_cls: 0.0491, s0.acc: 98.0117, s0.loss_bbox: 0.0584, s1.loss_cls: 0.0291, s1.acc: 97.5951, s1.loss_bbox: 0.1003, s2.loss_cls: 0.0216, s2.acc: 95.9759, s2.loss_bbox: 0.0828, loss: 0.3593\n2022-10-21 17:07:27,190 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:07:27,191 - mmdet - INFO - Epoch [5][600/600]\tlr: 2.000e-03, eta: 2:24:45, time: 0.569, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0137, s0.loss_cls: 0.0610, s0.acc: 97.4805, s0.loss_bbox: 0.0667, s1.loss_cls: 0.0355, s1.acc: 97.0604, s1.loss_bbox: 0.1064, s2.loss_cls: 0.0238, s2.acc: 95.8855, s2.loss_bbox: 0.0805, loss: 0.3928\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.4 task/s, elapsed: 95s, ETA:     0s2022-10-21 17:09:02,402 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.77s).\nAccumulating evaluation results...\nDONE (t=0.14s).\n2022-10-21 17:09:03,336 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.816\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.332\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.249\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.550\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.468\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.468\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.346\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.700\n\n2022-10-21 17:09:03,345 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:09:03,346 - mmdet - INFO - Epoch(val) [5][800]\tbbox_mAP: 0.3960, bbox_mAP_50: 0.8160, bbox_mAP_75: 0.3320, bbox_mAP_s: 0.2490, bbox_mAP_m: 0.5500, bbox_mAP_l: 0.6330, bbox_mAP_copypaste: 0.396 0.816 0.332 0.249 0.550 0.633\n2022-10-21 17:09:34,411 - mmdet - INFO - Epoch [6][50/600]\tlr: 2.000e-03, eta: 2:24:27, time: 0.621, data_time: 0.057, memory: 5826, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0132, s0.loss_cls: 0.0485, s0.acc: 97.9414, s0.loss_bbox: 0.0553, s1.loss_cls: 0.0290, s1.acc: 97.5917, s1.loss_bbox: 0.0957, s2.loss_cls: 0.0217, s2.acc: 96.1948, s2.loss_bbox: 0.0782, loss: 0.3445\n2022-10-21 17:10:02,640 - mmdet - INFO - Epoch [6][100/600]\tlr: 2.000e-03, eta: 2:23:54, time: 0.565, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0106, s0.loss_cls: 0.0472, s0.acc: 98.0586, s0.loss_bbox: 0.0530, s1.loss_cls: 0.0270, s1.acc: 97.7625, s1.loss_bbox: 0.0844, s2.loss_cls: 0.0181, s2.acc: 96.9322, s2.loss_bbox: 0.0672, loss: 0.3119\n2022-10-21 17:10:30,786 - mmdet - INFO - Epoch [6][150/600]\tlr: 2.000e-03, eta: 2:23:21, time: 0.563, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0519, s0.acc: 97.8652, s0.loss_bbox: 0.0608, s1.loss_cls: 0.0314, s1.acc: 97.4007, s1.loss_bbox: 0.1081, s2.loss_cls: 0.0227, s2.acc: 96.0152, s2.loss_bbox: 0.0851, loss: 0.3782\n2022-10-21 17:10:59,124 - mmdet - INFO - Epoch [6][200/600]\tlr: 2.000e-03, eta: 2:22:49, time: 0.567, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0142, s0.loss_cls: 0.0572, s0.acc: 97.6855, s0.loss_bbox: 0.0676, s1.loss_cls: 0.0348, s1.acc: 97.0826, s1.loss_bbox: 0.1012, s2.loss_cls: 0.0242, s2.acc: 95.8311, s2.loss_bbox: 0.0745, loss: 0.3781\n2022-10-21 17:11:27,592 - mmdet - INFO - Epoch [6][250/600]\tlr: 2.000e-03, eta: 2:22:18, time: 0.569, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0552, s0.acc: 97.6680, s0.loss_bbox: 0.0626, s1.loss_cls: 0.0327, s1.acc: 97.2666, s1.loss_bbox: 0.1064, s2.loss_cls: 0.0252, s2.acc: 95.6804, s2.loss_bbox: 0.0853, loss: 0.3844\n2022-10-21 17:11:56,167 - mmdet - INFO - Epoch [6][300/600]\tlr: 2.000e-03, eta: 2:21:48, time: 0.571, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0143, s0.loss_cls: 0.0575, s0.acc: 97.6816, s0.loss_bbox: 0.0669, s1.loss_cls: 0.0348, s1.acc: 97.1542, s1.loss_bbox: 0.1115, s2.loss_cls: 0.0247, s2.acc: 95.2821, s2.loss_bbox: 0.0866, loss: 0.4005\n2022-10-21 17:12:24,288 - mmdet - INFO - Epoch [6][350/600]\tlr: 2.000e-03, eta: 2:21:15, time: 0.562, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0103, s0.loss_cls: 0.0452, s0.acc: 98.0840, s0.loss_bbox: 0.0510, s1.loss_cls: 0.0254, s1.acc: 97.9126, s1.loss_bbox: 0.0945, s2.loss_cls: 0.0201, s2.acc: 96.5502, s2.loss_bbox: 0.0780, loss: 0.3272\n2022-10-21 17:12:52,829 - mmdet - INFO - Epoch [6][400/600]\tlr: 2.000e-03, eta: 2:20:44, time: 0.571, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.0522, s0.acc: 97.8672, s0.loss_bbox: 0.0588, s1.loss_cls: 0.0294, s1.acc: 97.5874, s1.loss_bbox: 0.1019, s2.loss_cls: 0.0220, s2.acc: 96.3406, s2.loss_bbox: 0.0766, loss: 0.3599\n2022-10-21 17:13:21,103 - mmdet - INFO - Epoch [6][450/600]\tlr: 2.000e-03, eta: 2:20:13, time: 0.565, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0129, s0.loss_cls: 0.0504, s0.acc: 97.8945, s0.loss_bbox: 0.0610, s1.loss_cls: 0.0315, s1.acc: 97.4608, s1.loss_bbox: 0.1036, s2.loss_cls: 0.0239, s2.acc: 95.7636, s2.loss_bbox: 0.0837, loss: 0.3708\n2022-10-21 17:13:49,445 - mmdet - INFO - Epoch [6][500/600]\tlr: 2.000e-03, eta: 2:19:42, time: 0.567, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0109, s0.loss_cls: 0.0445, s0.acc: 98.1426, s0.loss_bbox: 0.0522, s1.loss_cls: 0.0261, s1.acc: 97.7749, s1.loss_bbox: 0.0949, s2.loss_cls: 0.0204, s2.acc: 96.4083, s2.loss_bbox: 0.0736, loss: 0.3258\n2022-10-21 17:14:17,983 - mmdet - INFO - Epoch [6][550/600]\tlr: 2.000e-03, eta: 2:19:11, time: 0.571, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0135, s0.loss_cls: 0.0522, s0.acc: 97.7793, s0.loss_bbox: 0.0660, s1.loss_cls: 0.0307, s1.acc: 97.4379, s1.loss_bbox: 0.1022, s2.loss_cls: 0.0204, s2.acc: 96.3744, s2.loss_bbox: 0.0752, loss: 0.3672\n2022-10-21 17:14:46,448 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:14:46,448 - mmdet - INFO - Epoch [6][600/600]\tlr: 2.000e-03, eta: 2:18:40, time: 0.569, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0145, s0.loss_cls: 0.0527, s0.acc: 97.8125, s0.loss_bbox: 0.0659, s1.loss_cls: 0.0301, s1.acc: 97.4250, s1.loss_bbox: 0.1023, s2.loss_cls: 0.0208, s2.acc: 96.4249, s2.loss_bbox: 0.0771, loss: 0.3687\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.5 task/s, elapsed: 95s, ETA:     0s2022-10-21 17:16:21,204 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.59s).\nAccumulating evaluation results...\nDONE (t=0.13s).\n2022-10-21 17:16:21,941 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.844\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.346\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.266\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.547\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.663\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.362\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.604\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.720\n\n2022-10-21 17:16:21,950 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:16:21,951 - mmdet - INFO - Epoch(val) [6][800]\tbbox_mAP: 0.4110, bbox_mAP_50: 0.8440, bbox_mAP_75: 0.3460, bbox_mAP_s: 0.2660, bbox_mAP_m: 0.5470, bbox_mAP_l: 0.6630, bbox_mAP_copypaste: 0.411 0.844 0.346 0.266 0.547 0.663\n2022-10-21 17:16:52,833 - mmdet - INFO - Epoch [7][50/600]\tlr: 2.000e-03, eta: 2:18:19, time: 0.617, data_time: 0.056, memory: 5826, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0146, s0.loss_cls: 0.0497, s0.acc: 97.9883, s0.loss_bbox: 0.0581, s1.loss_cls: 0.0279, s1.acc: 97.7101, s1.loss_bbox: 0.0966, s2.loss_cls: 0.0222, s2.acc: 96.1347, s2.loss_bbox: 0.0744, loss: 0.3485\n2022-10-21 17:17:21,380 - mmdet - INFO - Epoch [7][100/600]\tlr: 2.000e-03, eta: 2:17:49, time: 0.571, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0131, s0.loss_cls: 0.0535, s0.acc: 97.8340, s0.loss_bbox: 0.0564, s1.loss_cls: 0.0294, s1.acc: 97.6069, s1.loss_bbox: 0.0893, s2.loss_cls: 0.0202, s2.acc: 96.5347, s2.loss_bbox: 0.0681, loss: 0.3349\n2022-10-21 17:17:49,732 - mmdet - INFO - Epoch [7][150/600]\tlr: 2.000e-03, eta: 2:17:18, time: 0.567, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0141, s0.loss_cls: 0.0435, s0.acc: 98.2051, s0.loss_bbox: 0.0497, s1.loss_cls: 0.0278, s1.acc: 97.6740, s1.loss_bbox: 0.0907, s2.loss_cls: 0.0202, s2.acc: 96.5716, s2.loss_bbox: 0.0787, loss: 0.3281\n2022-10-21 17:18:18,041 - mmdet - INFO - Epoch [7][200/600]\tlr: 2.000e-03, eta: 2:16:47, time: 0.566, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0106, s0.loss_cls: 0.0415, s0.acc: 98.2168, s0.loss_bbox: 0.0506, s1.loss_cls: 0.0258, s1.acc: 97.9012, s1.loss_bbox: 0.0922, s2.loss_cls: 0.0187, s2.acc: 96.7462, s2.loss_bbox: 0.0821, loss: 0.3241\n2022-10-21 17:18:46,149 - mmdet - INFO - Epoch [7][250/600]\tlr: 2.000e-03, eta: 2:16:15, time: 0.562, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0123, s0.loss_cls: 0.0519, s0.acc: 97.8906, s0.loss_bbox: 0.0557, s1.loss_cls: 0.0331, s1.acc: 97.2211, s1.loss_bbox: 0.0982, s2.loss_cls: 0.0232, s2.acc: 95.8685, s2.loss_bbox: 0.0787, loss: 0.3562\n2022-10-21 17:19:14,483 - mmdet - INFO - Epoch [7][300/600]\tlr: 2.000e-03, eta: 2:15:44, time: 0.567, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0126, s0.loss_cls: 0.0472, s0.acc: 98.0352, s0.loss_bbox: 0.0526, s1.loss_cls: 0.0282, s1.acc: 97.6893, s1.loss_bbox: 0.0894, s2.loss_cls: 0.0189, s2.acc: 96.6977, s2.loss_bbox: 0.0725, loss: 0.3252\n2022-10-21 17:19:42,886 - mmdet - INFO - Epoch [7][350/600]\tlr: 2.000e-03, eta: 2:15:14, time: 0.568, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0115, s0.loss_cls: 0.0491, s0.acc: 97.9355, s0.loss_bbox: 0.0567, s1.loss_cls: 0.0292, s1.acc: 97.5489, s1.loss_bbox: 0.1003, s2.loss_cls: 0.0229, s2.acc: 95.9078, s2.loss_bbox: 0.0829, loss: 0.3554\n2022-10-21 17:20:11,222 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:20:11,222 - mmdet - INFO - Epoch [7][400/600]\tlr: 2.000e-03, eta: 2:14:43, time: 0.567, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0124, s0.loss_cls: 0.0510, s0.acc: 97.9043, s0.loss_bbox: 0.0548, s1.loss_cls: 0.0295, s1.acc: 97.4813, s1.loss_bbox: 0.0957, s2.loss_cls: 0.0197, s2.acc: 96.6195, s2.loss_bbox: 0.0798, loss: 0.3462\n2022-10-21 17:20:39,347 - mmdet - INFO - Epoch [7][450/600]\tlr: 2.000e-03, eta: 2:14:11, time: 0.562, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0110, s0.loss_cls: 0.0453, s0.acc: 98.1289, s0.loss_bbox: 0.0473, s1.loss_cls: 0.0266, s1.acc: 97.7791, s1.loss_bbox: 0.0847, s2.loss_cls: 0.0188, s2.acc: 96.5906, s2.loss_bbox: 0.0706, loss: 0.3077\n2022-10-21 17:21:07,670 - mmdet - INFO - Epoch [7][500/600]\tlr: 2.000e-03, eta: 2:13:41, time: 0.566, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0143, s0.loss_cls: 0.0520, s0.acc: 97.9395, s0.loss_bbox: 0.0562, s1.loss_cls: 0.0300, s1.acc: 97.5094, s1.loss_bbox: 0.0911, s2.loss_cls: 0.0210, s2.acc: 96.5593, s2.loss_bbox: 0.0768, loss: 0.3456\n2022-10-21 17:21:36,056 - mmdet - INFO - Epoch [7][550/600]\tlr: 2.000e-03, eta: 2:13:10, time: 0.568, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0111, s0.loss_cls: 0.0469, s0.acc: 98.0449, s0.loss_bbox: 0.0544, s1.loss_cls: 0.0267, s1.acc: 97.7738, s1.loss_bbox: 0.0943, s2.loss_cls: 0.0215, s2.acc: 96.1280, s2.loss_bbox: 0.0732, loss: 0.3321\n2022-10-21 17:22:04,446 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:22:04,447 - mmdet - INFO - Epoch [7][600/600]\tlr: 2.000e-03, eta: 2:12:40, time: 0.568, data_time: 0.013, memory: 5826, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0123, s0.loss_cls: 0.0491, s0.acc: 97.9961, s0.loss_bbox: 0.0578, s1.loss_cls: 0.0280, s1.acc: 97.7453, s1.loss_bbox: 0.1000, s2.loss_cls: 0.0198, s2.acc: 96.4694, s2.loss_bbox: 0.0828, loss: 0.3528\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.5 task/s, elapsed: 94s, ETA:     0s2022-10-21 17:23:38,968 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.65s).\nAccumulating evaluation results...\nDONE (t=0.13s).\n2022-10-21 17:23:39,763 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.839\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.258\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.248\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.500\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.593\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.348\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.563\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.642\n\n2022-10-21 17:23:39,770 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:23:39,771 - mmdet - INFO - Epoch(val) [7][800]\tbbox_mAP: 0.3770, bbox_mAP_50: 0.8390, bbox_mAP_75: 0.2580, bbox_mAP_s: 0.2480, bbox_mAP_m: 0.5000, bbox_mAP_l: 0.5930, bbox_mAP_copypaste: 0.377 0.839 0.258 0.248 0.500 0.593\n2022-10-21 17:24:10,279 - mmdet - INFO - Epoch [8][50/600]\tlr: 2.000e-03, eta: 2:12:16, time: 0.610, data_time: 0.056, memory: 5826, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0116, s0.loss_cls: 0.0504, s0.acc: 97.9805, s0.loss_bbox: 0.0527, s1.loss_cls: 0.0293, s1.acc: 97.6665, s1.loss_bbox: 0.0918, s2.loss_cls: 0.0219, s2.acc: 96.3135, s2.loss_bbox: 0.0739, loss: 0.3348\n2022-10-21 17:24:38,724 - mmdet - INFO - Epoch [8][100/600]\tlr: 2.000e-03, eta: 2:11:46, time: 0.569, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0130, s0.loss_cls: 0.0470, s0.acc: 98.0703, s0.loss_bbox: 0.0544, s1.loss_cls: 0.0269, s1.acc: 97.7722, s1.loss_bbox: 0.0918, s2.loss_cls: 0.0207, s2.acc: 96.3189, s2.loss_bbox: 0.0733, loss: 0.3306\n2022-10-21 17:25:06,884 - mmdet - INFO - Epoch [8][150/600]\tlr: 2.000e-03, eta: 2:11:15, time: 0.563, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0109, s0.loss_cls: 0.0388, s0.acc: 98.3867, s0.loss_bbox: 0.0432, s1.loss_cls: 0.0222, s1.acc: 98.1817, s1.loss_bbox: 0.0762, s2.loss_cls: 0.0163, s2.acc: 97.2292, s2.loss_bbox: 0.0657, loss: 0.2762\n2022-10-21 17:25:35,320 - mmdet - INFO - Epoch [8][200/600]\tlr: 2.000e-03, eta: 2:10:45, time: 0.569, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0119, s0.loss_cls: 0.0431, s0.acc: 98.2363, s0.loss_bbox: 0.0503, s1.loss_cls: 0.0243, s1.acc: 97.9805, s1.loss_bbox: 0.0901, s2.loss_cls: 0.0175, s2.acc: 96.9022, s2.loss_bbox: 0.0762, loss: 0.3165\n2022-10-21 17:26:03,786 - mmdet - INFO - Epoch [8][250/600]\tlr: 2.000e-03, eta: 2:10:15, time: 0.569, data_time: 0.013, memory: 5826, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0109, s0.loss_cls: 0.0410, s0.acc: 98.3438, s0.loss_bbox: 0.0426, s1.loss_cls: 0.0233, s1.acc: 98.0956, s1.loss_bbox: 0.0773, s2.loss_cls: 0.0167, s2.acc: 97.0520, s2.loss_bbox: 0.0685, loss: 0.2834\n2022-10-21 17:26:32,116 - mmdet - INFO - Epoch [8][300/600]\tlr: 2.000e-03, eta: 2:09:45, time: 0.567, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0088, s0.loss_cls: 0.0391, s0.acc: 98.3809, s0.loss_bbox: 0.0453, s1.loss_cls: 0.0222, s1.acc: 98.1202, s1.loss_bbox: 0.0785, s2.loss_cls: 0.0157, s2.acc: 97.2645, s2.loss_bbox: 0.0644, loss: 0.2768\n2022-10-21 17:27:00,634 - mmdet - INFO - Epoch [8][350/600]\tlr: 2.000e-03, eta: 2:09:15, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0501, s0.acc: 97.8984, s0.loss_bbox: 0.0600, s1.loss_cls: 0.0288, s1.acc: 97.5916, s1.loss_bbox: 0.1030, s2.loss_cls: 0.0209, s2.acc: 96.2226, s2.loss_bbox: 0.0836, loss: 0.3635\n2022-10-21 17:27:28,927 - mmdet - INFO - Epoch [8][400/600]\tlr: 2.000e-03, eta: 2:08:44, time: 0.566, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0124, s0.loss_cls: 0.0444, s0.acc: 98.1094, s0.loss_bbox: 0.0546, s1.loss_cls: 0.0267, s1.acc: 97.8098, s1.loss_bbox: 0.0949, s2.loss_cls: 0.0204, s2.acc: 96.4326, s2.loss_bbox: 0.0773, loss: 0.3334\n2022-10-21 17:27:57,500 - mmdet - INFO - Epoch [8][450/600]\tlr: 2.000e-03, eta: 2:08:15, time: 0.571, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0118, s0.loss_cls: 0.0425, s0.acc: 98.2480, s0.loss_bbox: 0.0483, s1.loss_cls: 0.0250, s1.acc: 97.8785, s1.loss_bbox: 0.0872, s2.loss_cls: 0.0176, s2.acc: 97.0037, s2.loss_bbox: 0.0761, loss: 0.3108\n2022-10-21 17:28:25,805 - mmdet - INFO - Epoch [8][500/600]\tlr: 2.000e-03, eta: 2:07:45, time: 0.566, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0120, s0.loss_cls: 0.0432, s0.acc: 98.1719, s0.loss_bbox: 0.0468, s1.loss_cls: 0.0243, s1.acc: 98.0539, s1.loss_bbox: 0.0884, s2.loss_cls: 0.0198, s2.acc: 96.5662, s2.loss_bbox: 0.0722, loss: 0.3093\n2022-10-21 17:28:54,118 - mmdet - INFO - Epoch [8][550/600]\tlr: 2.000e-03, eta: 2:07:14, time: 0.566, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0139, s0.loss_cls: 0.0512, s0.acc: 97.8125, s0.loss_bbox: 0.0618, s1.loss_cls: 0.0285, s1.acc: 97.5997, s1.loss_bbox: 0.1036, s2.loss_cls: 0.0201, s2.acc: 96.3134, s2.loss_bbox: 0.0832, loss: 0.3654\n2022-10-21 17:29:22,341 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:29:22,341 - mmdet - INFO - Epoch [8][600/600]\tlr: 2.000e-03, eta: 2:06:44, time: 0.564, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0141, s0.loss_cls: 0.0629, s0.acc: 97.3867, s0.loss_bbox: 0.0646, s1.loss_cls: 0.0371, s1.acc: 96.8506, s1.loss_bbox: 0.1026, s2.loss_cls: 0.0236, s2.acc: 95.7104, s2.loss_bbox: 0.0760, loss: 0.3864\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.4 task/s, elapsed: 95s, ETA:     0s2022-10-21 17:30:57,593 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.90s).\nAccumulating evaluation results...\nDONE (t=0.14s).\n2022-10-21 17:30:58,776 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.844\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.287\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.270\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.519\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.611\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.471\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.471\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.368\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.598\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.686\n\n2022-10-21 17:30:58,784 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:30:58,784 - mmdet - INFO - Epoch(val) [8][800]\tbbox_mAP: 0.3930, bbox_mAP_50: 0.8440, bbox_mAP_75: 0.2870, bbox_mAP_s: 0.2700, bbox_mAP_m: 0.5190, bbox_mAP_l: 0.6110, bbox_mAP_copypaste: 0.393 0.844 0.287 0.270 0.519 0.611\n2022-10-21 17:31:29,626 - mmdet - INFO - Epoch [9][50/600]\tlr: 2.000e-04, eta: 2:06:21, time: 0.617, data_time: 0.057, memory: 5826, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0108, s0.loss_cls: 0.0461, s0.acc: 98.0879, s0.loss_bbox: 0.0490, s1.loss_cls: 0.0264, s1.acc: 97.8268, s1.loss_bbox: 0.0795, s2.loss_cls: 0.0179, s2.acc: 96.9525, s2.loss_bbox: 0.0674, loss: 0.3009\n2022-10-21 17:31:58,114 - mmdet - INFO - Epoch [9][100/600]\tlr: 2.000e-04, eta: 2:05:51, time: 0.570, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0107, s0.loss_cls: 0.0481, s0.acc: 97.9531, s0.loss_bbox: 0.0518, s1.loss_cls: 0.0254, s1.acc: 97.9045, s1.loss_bbox: 0.0903, s2.loss_cls: 0.0178, s2.acc: 96.9715, s2.loss_bbox: 0.0789, loss: 0.3257\n2022-10-21 17:32:26,722 - mmdet - INFO - Epoch [9][150/600]\tlr: 2.000e-04, eta: 2:05:22, time: 0.572, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0098, s0.loss_cls: 0.0422, s0.acc: 98.2773, s0.loss_bbox: 0.0435, s1.loss_cls: 0.0228, s1.acc: 98.1970, s1.loss_bbox: 0.0775, s2.loss_cls: 0.0161, s2.acc: 97.2529, s2.loss_bbox: 0.0683, loss: 0.2827\n2022-10-21 17:32:54,935 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:32:54,936 - mmdet - INFO - Epoch [9][200/600]\tlr: 2.000e-04, eta: 2:04:51, time: 0.564, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0107, s0.loss_cls: 0.0415, s0.acc: 98.2988, s0.loss_bbox: 0.0454, s1.loss_cls: 0.0230, s1.acc: 98.1462, s1.loss_bbox: 0.0780, s2.loss_cls: 0.0157, s2.acc: 97.2508, s2.loss_bbox: 0.0656, loss: 0.2822\n2022-10-21 17:33:23,350 - mmdet - INFO - Epoch [9][250/600]\tlr: 2.000e-04, eta: 2:04:21, time: 0.568, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0104, s0.loss_cls: 0.0369, s0.acc: 98.4570, s0.loss_bbox: 0.0406, s1.loss_cls: 0.0222, s1.acc: 98.0976, s1.loss_bbox: 0.0765, s2.loss_cls: 0.0149, s2.acc: 97.4487, s2.loss_bbox: 0.0694, loss: 0.2734\n2022-10-21 17:33:51,528 - mmdet - INFO - Epoch [9][300/600]\tlr: 2.000e-04, eta: 2:03:51, time: 0.564, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0095, s0.loss_cls: 0.0408, s0.acc: 98.3613, s0.loss_bbox: 0.0394, s1.loss_cls: 0.0218, s1.acc: 98.2706, s1.loss_bbox: 0.0727, s2.loss_cls: 0.0156, s2.acc: 97.3895, s2.loss_bbox: 0.0640, loss: 0.2658\n2022-10-21 17:34:20,010 - mmdet - INFO - Epoch [9][350/600]\tlr: 2.000e-04, eta: 2:03:21, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0100, s0.loss_cls: 0.0407, s0.acc: 98.3027, s0.loss_bbox: 0.0425, s1.loss_cls: 0.0222, s1.acc: 98.1620, s1.loss_bbox: 0.0767, s2.loss_cls: 0.0164, s2.acc: 97.2739, s2.loss_bbox: 0.0681, loss: 0.2793\n2022-10-21 17:34:48,315 - mmdet - INFO - Epoch [9][400/600]\tlr: 2.000e-04, eta: 2:02:51, time: 0.566, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0102, s0.loss_cls: 0.0378, s0.acc: 98.4668, s0.loss_bbox: 0.0411, s1.loss_cls: 0.0200, s1.acc: 98.3709, s1.loss_bbox: 0.0775, s2.loss_cls: 0.0141, s2.acc: 97.7162, s2.loss_bbox: 0.0701, loss: 0.2734\n2022-10-21 17:35:16,807 - mmdet - INFO - Epoch [9][450/600]\tlr: 2.000e-04, eta: 2:02:22, time: 0.570, data_time: 0.013, memory: 5826, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0085, s0.loss_cls: 0.0379, s0.acc: 98.4004, s0.loss_bbox: 0.0376, s1.loss_cls: 0.0208, s1.acc: 98.2612, s1.loss_bbox: 0.0723, s2.loss_cls: 0.0160, s2.acc: 97.3890, s2.loss_bbox: 0.0604, loss: 0.2558\n2022-10-21 17:35:44,914 - mmdet - INFO - Epoch [9][500/600]\tlr: 2.000e-04, eta: 2:01:51, time: 0.562, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0089, s0.loss_cls: 0.0352, s0.acc: 98.5605, s0.loss_bbox: 0.0352, s1.loss_cls: 0.0199, s1.acc: 98.3930, s1.loss_bbox: 0.0643, s2.loss_cls: 0.0136, s2.acc: 97.5523, s2.loss_bbox: 0.0563, loss: 0.2356\n2022-10-21 17:36:13,056 - mmdet - INFO - Epoch [9][550/600]\tlr: 2.000e-04, eta: 2:01:21, time: 0.563, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0117, s0.loss_cls: 0.0472, s0.acc: 98.0488, s0.loss_bbox: 0.0517, s1.loss_cls: 0.0246, s1.acc: 98.0594, s1.loss_bbox: 0.0858, s2.loss_cls: 0.0172, s2.acc: 97.0030, s2.loss_bbox: 0.0722, loss: 0.3137\n2022-10-21 17:36:41,221 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:36:41,222 - mmdet - INFO - Epoch [9][600/600]\tlr: 2.000e-04, eta: 2:00:51, time: 0.563, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0100, s0.loss_cls: 0.0398, s0.acc: 98.3320, s0.loss_bbox: 0.0419, s1.loss_cls: 0.0230, s1.acc: 98.0966, s1.loss_bbox: 0.0741, s2.loss_cls: 0.0159, s2.acc: 97.2204, s2.loss_bbox: 0.0600, loss: 0.2669\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.5 task/s, elapsed: 95s, ETA:     0s2022-10-21 17:38:15,945 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.56s).\nAccumulating evaluation results...\nDONE (t=0.14s).\n2022-10-21 17:38:16,661 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.848\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.335\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.268\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.553\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.650\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.473\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.473\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.358\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.614\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.707\n\n2022-10-21 17:38:16,669 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:38:16,669 - mmdet - INFO - Epoch(val) [9][800]\tbbox_mAP: 0.4110, bbox_mAP_50: 0.8480, bbox_mAP_75: 0.3350, bbox_mAP_s: 0.2680, bbox_mAP_m: 0.5530, bbox_mAP_l: 0.6500, bbox_mAP_copypaste: 0.411 0.848 0.335 0.268 0.553 0.650\n2022-10-21 17:38:47,391 - mmdet - INFO - Epoch [10][50/600]\tlr: 2.000e-04, eta: 2:00:26, time: 0.614, data_time: 0.059, memory: 5826, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0110, s0.loss_cls: 0.0459, s0.acc: 98.0332, s0.loss_bbox: 0.0510, s1.loss_cls: 0.0244, s1.acc: 97.8757, s1.loss_bbox: 0.0819, s2.loss_cls: 0.0156, s2.acc: 97.2315, s2.loss_bbox: 0.0705, loss: 0.3037\n2022-10-21 17:39:16,102 - mmdet - INFO - Epoch [10][100/600]\tlr: 2.000e-04, eta: 1:59:57, time: 0.574, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0088, s0.loss_cls: 0.0385, s0.acc: 98.4336, s0.loss_bbox: 0.0422, s1.loss_cls: 0.0227, s1.acc: 98.0548, s1.loss_bbox: 0.0762, s2.loss_cls: 0.0151, s2.acc: 97.4271, s2.loss_bbox: 0.0661, loss: 0.2714\n2022-10-21 17:39:44,552 - mmdet - INFO - Epoch [10][150/600]\tlr: 2.000e-04, eta: 1:59:28, time: 0.569, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0101, s0.loss_cls: 0.0373, s0.acc: 98.4844, s0.loss_bbox: 0.0378, s1.loss_cls: 0.0195, s1.acc: 98.3785, s1.loss_bbox: 0.0662, s2.loss_cls: 0.0134, s2.acc: 97.7311, s2.loss_bbox: 0.0599, loss: 0.2471\n2022-10-21 17:40:12,891 - mmdet - INFO - Epoch [10][200/600]\tlr: 2.000e-04, eta: 1:58:58, time: 0.567, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0090, s0.loss_cls: 0.0357, s0.acc: 98.5332, s0.loss_bbox: 0.0380, s1.loss_cls: 0.0188, s1.acc: 98.4775, s1.loss_bbox: 0.0726, s2.loss_cls: 0.0146, s2.acc: 97.5213, s2.loss_bbox: 0.0640, loss: 0.2552\n2022-10-21 17:40:41,146 - mmdet - INFO - Epoch [10][250/600]\tlr: 2.000e-04, eta: 1:58:28, time: 0.565, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0093, s0.loss_cls: 0.0364, s0.acc: 98.4316, s0.loss_bbox: 0.0370, s1.loss_cls: 0.0204, s1.acc: 98.3612, s1.loss_bbox: 0.0701, s2.loss_cls: 0.0154, s2.acc: 97.4813, s2.loss_bbox: 0.0641, loss: 0.2547\n2022-10-21 17:41:09,602 - mmdet - INFO - Epoch [10][300/600]\tlr: 2.000e-04, eta: 1:57:59, time: 0.569, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0103, s0.loss_cls: 0.0364, s0.acc: 98.5391, s0.loss_bbox: 0.0427, s1.loss_cls: 0.0208, s1.acc: 98.3213, s1.loss_bbox: 0.0726, s2.loss_cls: 0.0147, s2.acc: 97.4845, s2.loss_bbox: 0.0594, loss: 0.2591\n2022-10-21 17:41:37,836 - mmdet - INFO - Epoch [10][350/600]\tlr: 2.000e-04, eta: 1:57:29, time: 0.565, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0095, s0.loss_cls: 0.0404, s0.acc: 98.3770, s0.loss_bbox: 0.0421, s1.loss_cls: 0.0221, s1.acc: 98.0985, s1.loss_bbox: 0.0711, s2.loss_cls: 0.0147, s2.acc: 97.5427, s2.loss_bbox: 0.0611, loss: 0.2632\n2022-10-21 17:42:06,322 - mmdet - INFO - Epoch [10][400/600]\tlr: 2.000e-04, eta: 1:56:59, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0087, s0.loss_cls: 0.0326, s0.acc: 98.6445, s0.loss_bbox: 0.0349, s1.loss_cls: 0.0189, s1.acc: 98.4737, s1.loss_bbox: 0.0666, s2.loss_cls: 0.0136, s2.acc: 97.6553, s2.loss_bbox: 0.0582, loss: 0.2354\n2022-10-21 17:42:34,749 - mmdet - INFO - Epoch [10][450/600]\tlr: 2.000e-04, eta: 1:56:30, time: 0.569, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0098, s0.loss_cls: 0.0391, s0.acc: 98.4258, s0.loss_bbox: 0.0394, s1.loss_cls: 0.0197, s1.acc: 98.3986, s1.loss_bbox: 0.0697, s2.loss_cls: 0.0144, s2.acc: 97.5873, s2.loss_bbox: 0.0594, loss: 0.2538\n2022-10-21 17:43:02,877 - mmdet - INFO - Epoch [10][500/600]\tlr: 2.000e-04, eta: 1:56:00, time: 0.563, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0106, s0.loss_cls: 0.0348, s0.acc: 98.6133, s0.loss_bbox: 0.0391, s1.loss_cls: 0.0202, s1.acc: 98.3502, s1.loss_bbox: 0.0683, s2.loss_cls: 0.0147, s2.acc: 97.4220, s2.loss_bbox: 0.0597, loss: 0.2501\n2022-10-21 17:43:30,966 - mmdet - INFO - Epoch [10][550/600]\tlr: 2.000e-04, eta: 1:55:30, time: 0.562, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0087, s0.loss_cls: 0.0350, s0.acc: 98.5391, s0.loss_bbox: 0.0354, s1.loss_cls: 0.0191, s1.acc: 98.4365, s1.loss_bbox: 0.0627, s2.loss_cls: 0.0128, s2.acc: 97.9157, s2.loss_bbox: 0.0573, loss: 0.2338\n2022-10-21 17:43:59,163 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:43:59,163 - mmdet - INFO - Epoch [10][600/600]\tlr: 2.000e-04, eta: 1:55:00, time: 0.564, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0086, s0.loss_cls: 0.0297, s0.acc: 98.7949, s0.loss_bbox: 0.0349, s1.loss_cls: 0.0181, s1.acc: 98.5726, s1.loss_bbox: 0.0671, s2.loss_cls: 0.0153, s2.acc: 97.6179, s2.loss_bbox: 0.0600, loss: 0.2352\n2022-10-21 17:43:59,241 - mmdet - INFO - Saving checkpoint at 10 epochs\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.4 task/s, elapsed: 95s, ETA:     0s2022-10-21 17:45:36,623 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.58s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n2022-10-21 17:45:37,458 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.848\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.340\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.268\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.547\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.650\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.360\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.609\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.703\n\n2022-10-21 17:45:37,465 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:45:37,465 - mmdet - INFO - Epoch(val) [10][800]\tbbox_mAP: 0.4100, bbox_mAP_50: 0.8480, bbox_mAP_75: 0.3400, bbox_mAP_s: 0.2680, bbox_mAP_m: 0.5470, bbox_mAP_l: 0.6500, bbox_mAP_copypaste: 0.410 0.848 0.340 0.268 0.547 0.650\n2022-10-21 17:46:08,031 - mmdet - INFO - Epoch [11][50/600]\tlr: 2.000e-04, eta: 1:54:35, time: 0.611, data_time: 0.056, memory: 5826, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0099, s0.loss_cls: 0.0390, s0.acc: 98.3750, s0.loss_bbox: 0.0443, s1.loss_cls: 0.0221, s1.acc: 98.2169, s1.loss_bbox: 0.0750, s2.loss_cls: 0.0157, s2.acc: 97.4357, s2.loss_bbox: 0.0610, loss: 0.2698\n2022-10-21 17:46:36,552 - mmdet - INFO - Epoch [11][100/600]\tlr: 2.000e-04, eta: 1:54:05, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0092, s0.loss_cls: 0.0327, s0.acc: 98.6035, s0.loss_bbox: 0.0359, s1.loss_cls: 0.0187, s1.acc: 98.3937, s1.loss_bbox: 0.0618, s2.loss_cls: 0.0127, s2.acc: 97.8770, s2.loss_bbox: 0.0516, loss: 0.2239\n2022-10-21 17:47:04,984 - mmdet - INFO - Epoch [11][150/600]\tlr: 2.000e-04, eta: 1:53:36, time: 0.569, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0093, s0.loss_cls: 0.0379, s0.acc: 98.3906, s0.loss_bbox: 0.0369, s1.loss_cls: 0.0194, s1.acc: 98.3932, s1.loss_bbox: 0.0666, s2.loss_cls: 0.0137, s2.acc: 97.7904, s2.loss_bbox: 0.0594, loss: 0.2458\n2022-10-21 17:47:33,300 - mmdet - INFO - Epoch [11][200/600]\tlr: 2.000e-04, eta: 1:53:06, time: 0.566, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0086, s0.loss_cls: 0.0351, s0.acc: 98.5488, s0.loss_bbox: 0.0312, s1.loss_cls: 0.0176, s1.acc: 98.4640, s1.loss_bbox: 0.0586, s2.loss_cls: 0.0124, s2.acc: 98.0719, s2.loss_bbox: 0.0541, loss: 0.2190\n2022-10-21 17:48:01,795 - mmdet - INFO - Epoch [11][250/600]\tlr: 2.000e-04, eta: 1:52:37, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0082, s0.loss_cls: 0.0334, s0.acc: 98.6621, s0.loss_bbox: 0.0323, s1.loss_cls: 0.0194, s1.acc: 98.3467, s1.loss_bbox: 0.0611, s2.loss_cls: 0.0131, s2.acc: 97.6636, s2.loss_bbox: 0.0517, loss: 0.2213\n2022-10-21 17:48:30,066 - mmdet - INFO - Epoch [11][300/600]\tlr: 2.000e-04, eta: 1:52:07, time: 0.565, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0097, s0.loss_cls: 0.0378, s0.acc: 98.4336, s0.loss_bbox: 0.0408, s1.loss_cls: 0.0202, s1.acc: 98.3171, s1.loss_bbox: 0.0725, s2.loss_cls: 0.0146, s2.acc: 97.4765, s2.loss_bbox: 0.0625, loss: 0.2605\n2022-10-21 17:48:58,517 - mmdet - INFO - Epoch [11][350/600]\tlr: 2.000e-04, eta: 1:51:38, time: 0.569, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0080, s0.loss_cls: 0.0324, s0.acc: 98.6680, s0.loss_bbox: 0.0344, s1.loss_cls: 0.0182, s1.acc: 98.5235, s1.loss_bbox: 0.0663, s2.loss_cls: 0.0140, s2.acc: 97.5884, s2.loss_bbox: 0.0587, loss: 0.2343\n2022-10-21 17:49:26,854 - mmdet - INFO - Epoch [11][400/600]\tlr: 2.000e-04, eta: 1:51:09, time: 0.567, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0109, s0.loss_cls: 0.0417, s0.acc: 98.2949, s0.loss_bbox: 0.0457, s1.loss_cls: 0.0220, s1.acc: 98.2059, s1.loss_bbox: 0.0707, s2.loss_cls: 0.0151, s2.acc: 97.5996, s2.loss_bbox: 0.0601, loss: 0.2689\n2022-10-21 17:49:55,158 - mmdet - INFO - Epoch [11][450/600]\tlr: 2.000e-04, eta: 1:50:39, time: 0.566, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0100, s0.loss_cls: 0.0358, s0.acc: 98.6035, s0.loss_bbox: 0.0396, s1.loss_cls: 0.0193, s1.acc: 98.4072, s1.loss_bbox: 0.0686, s2.loss_cls: 0.0135, s2.acc: 97.6880, s2.loss_bbox: 0.0619, loss: 0.2510\n2022-10-21 17:50:23,656 - mmdet - INFO - Epoch [11][500/600]\tlr: 2.000e-04, eta: 1:50:10, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0102, s0.loss_cls: 0.0396, s0.acc: 98.3516, s0.loss_bbox: 0.0411, s1.loss_cls: 0.0215, s1.acc: 98.1374, s1.loss_bbox: 0.0708, s2.loss_cls: 0.0151, s2.acc: 97.4852, s2.loss_bbox: 0.0606, loss: 0.2614\n2022-10-21 17:50:51,804 - mmdet - INFO - Epoch [11][550/600]\tlr: 2.000e-04, eta: 1:49:40, time: 0.563, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0089, s0.loss_cls: 0.0301, s0.acc: 98.7539, s0.loss_bbox: 0.0323, s1.loss_cls: 0.0176, s1.acc: 98.6381, s1.loss_bbox: 0.0599, s2.loss_cls: 0.0121, s2.acc: 98.0038, s2.loss_bbox: 0.0541, loss: 0.2168\n2022-10-21 17:51:20,040 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:51:20,040 - mmdet - INFO - Epoch [11][600/600]\tlr: 2.000e-04, eta: 1:49:11, time: 0.565, data_time: 0.014, memory: 5826, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0104, s0.loss_cls: 0.0361, s0.acc: 98.5117, s0.loss_bbox: 0.0373, s1.loss_cls: 0.0194, s1.acc: 98.4454, s1.loss_bbox: 0.0706, s2.loss_cls: 0.0145, s2.acc: 97.5436, s2.loss_bbox: 0.0601, loss: 0.2506\n[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 800/800, 8.4 task/s, elapsed: 95s, ETA:     0s2022-10-21 17:52:55,393 - mmdet - INFO - Evaluating bbox...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.55s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n2022-10-21 17:52:56,071 - mmdet - INFO - \n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.839\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.333\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.263\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.544\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.651\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.467\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.467\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.352\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.607\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.708\n\n2022-10-21 17:52:56,078 - mmdet - INFO - Exp name: we_cascade_rcnn_r101_fpn.py\n2022-10-21 17:52:56,079 - mmdet - INFO - Epoch(val) [11][800]\tbbox_mAP: 0.4050, bbox_mAP_50: 0.8390, bbox_mAP_75: 0.3330, bbox_mAP_s: 0.2630, bbox_mAP_m: 0.5440, bbox_mAP_l: 0.6510, bbox_mAP_copypaste: 0.405 0.839 0.333 0.263 0.544 0.651\n2022-10-21 17:53:26,860 - mmdet - INFO - Epoch [12][50/600]\tlr: 2.000e-04, eta: 1:48:45, time: 0.615, data_time: 0.057, memory: 5826, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0085, s0.loss_cls: 0.0313, s0.acc: 98.7578, s0.loss_bbox: 0.0316, s1.loss_cls: 0.0168, s1.acc: 98.5809, s1.loss_bbox: 0.0612, s2.loss_cls: 0.0127, s2.acc: 97.8012, s2.loss_bbox: 0.0508, loss: 0.2144\n2022-10-21 17:53:55,130 - mmdet - INFO - Epoch [12][100/600]\tlr: 2.000e-04, eta: 1:48:16, time: 0.565, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0092, s0.loss_cls: 0.0341, s0.acc: 98.5332, s0.loss_bbox: 0.0360, s1.loss_cls: 0.0186, s1.acc: 98.4592, s1.loss_bbox: 0.0623, s2.loss_cls: 0.0136, s2.acc: 97.6644, s2.loss_bbox: 0.0531, loss: 0.2292\n2022-10-21 17:54:23,367 - mmdet - INFO - Epoch [12][150/600]\tlr: 2.000e-04, eta: 1:47:46, time: 0.565, data_time: 0.011, memory: 5826, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0083, s0.loss_cls: 0.0329, s0.acc: 98.6855, s0.loss_bbox: 0.0348, s1.loss_cls: 0.0184, s1.acc: 98.4452, s1.loss_bbox: 0.0588, s2.loss_cls: 0.0133, s2.acc: 97.7031, s2.loss_bbox: 0.0483, loss: 0.2177\n2022-10-21 17:54:51,861 - mmdet - INFO - Epoch [12][200/600]\tlr: 2.000e-04, eta: 1:47:17, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0080, s0.loss_cls: 0.0334, s0.acc: 98.5586, s0.loss_bbox: 0.0330, s1.loss_cls: 0.0174, s1.acc: 98.5322, s1.loss_bbox: 0.0637, s2.loss_cls: 0.0127, s2.acc: 97.9205, s2.loss_bbox: 0.0542, loss: 0.2240\n2022-10-21 17:55:20,069 - mmdet - INFO - Epoch [12][250/600]\tlr: 2.000e-04, eta: 1:46:47, time: 0.564, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0102, s0.loss_cls: 0.0330, s0.acc: 98.6289, s0.loss_bbox: 0.0378, s1.loss_cls: 0.0185, s1.acc: 98.4444, s1.loss_bbox: 0.0652, s2.loss_cls: 0.0130, s2.acc: 97.6924, s2.loss_bbox: 0.0530, loss: 0.2333\n2022-10-21 17:55:48,587 - mmdet - INFO - Epoch [12][300/600]\tlr: 2.000e-04, eta: 1:46:18, time: 0.570, data_time: 0.012, memory: 5826, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0102, s0.loss_cls: 0.0362, s0.acc: 98.4863, s0.loss_bbox: 0.0413, s1.loss_cls: 0.0187, s1.acc: 98.4579, s1.loss_bbox: 0.0712, s2.loss_cls: 0.0144, s2.acc: 97.4712, s2.loss_bbox: 0.0622, loss: 0.2574\n","output_type":"stream"}]},{"cell_type":"code","source":"cd faster_rcnn","metadata":{"execution":{"iopub.status.busy":"2022-10-21T14:07:25.679717Z","iopub.execute_input":"2022-10-21T14:07:25.680097Z","iopub.status.idle":"2022-10-21T14:07:25.687099Z","shell.execute_reply.started":"2022-10-21T14:07:25.680065Z","shell.execute_reply":"2022-10-21T14:07:25.685831Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"/kaggle/working/modified_mmdetection/configs/faster_rcnn\n","output_type":"stream"}]},{"cell_type":"code","source":"!python ../../tools/analysis_tools/get_flops.py 'we_cascade_rcnn_r101_fpn.py'","metadata":{"execution":{"iopub.status.busy":"2022-10-21T14:07:28.381836Z","iopub.execute_input":"2022-10-21T14:07:28.382242Z","iopub.status.idle":"2022-10-21T14:07:37.428606Z","shell.execute_reply.started":"2022-10-21T14:07:28.382207Z","shell.execute_reply":"2022-10-21T14:07:37.427377Z"},"scrolled":true,"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"CascadeRCNN(\n  87.919 M, 100.000% Params, 310.537 GFLOPs, 100.000% FLOPs, \n  (backbone): ResNet(\n    42.275 M, 48.084% Params, 160.15 GFLOPs, 51.572% FLOPs, \n    (conv1): Conv2d(0.0 M, 0.000% Params, 2.408 GFLOPs, 0.776% FLOPs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.033 GFLOPs, 0.011% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.005% FLOPs, inplace=True)\n    (maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.005% FLOPs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): ResLayer(\n      0.0 M, 0.000% Params, 13.885 GFLOPs, 4.471% FLOPs, \n      (0): Bottleneck(\n        0.0 M, 0.000% Params, 4.825 GFLOPs, 1.554% FLOPs, \n        (conv1): Conv2d(0.0 M, 0.000% Params, 0.262 GFLOPs, 0.084% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.0 M, 0.000% Params, 2.359 GFLOPs, 0.760% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.0 M, 0.000% Params, 1.049 GFLOPs, 0.338% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.0 M, 0.000% Params, 0.033 GFLOPs, 0.011% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.025 GFLOPs, 0.008% FLOPs, inplace=True)\n        (downsample): Sequential(\n          0.0 M, 0.000% Params, 1.081 GFLOPs, 0.348% FLOPs, \n          (0): Conv2d(0.0 M, 0.000% Params, 1.049 GFLOPs, 0.338% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(0.0 M, 0.000% Params, 0.033 GFLOPs, 0.011% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        0.0 M, 0.000% Params, 4.53 GFLOPs, 1.459% FLOPs, \n        (conv1): Conv2d(0.0 M, 0.000% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.0 M, 0.000% Params, 2.359 GFLOPs, 0.760% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.0 M, 0.000% Params, 1.049 GFLOPs, 0.338% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.0 M, 0.000% Params, 0.033 GFLOPs, 0.011% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.025 GFLOPs, 0.008% FLOPs, inplace=True)\n      )\n      (2): Bottleneck(\n        0.0 M, 0.000% Params, 4.53 GFLOPs, 1.459% FLOPs, \n        (conv1): Conv2d(0.0 M, 0.000% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.0 M, 0.000% Params, 2.359 GFLOPs, 0.760% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.0 M, 0.000% Params, 1.049 GFLOPs, 0.338% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.0 M, 0.000% Params, 0.033 GFLOPs, 0.011% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.025 GFLOPs, 0.008% FLOPs, inplace=True)\n      )\n    )\n    (layer2): ResLayer(\n      1.22 M, 1.387% Params, 21.154 GFLOPs, 6.812% FLOPs, \n      (0): Bottleneck(\n        0.379 M, 0.432% Params, 7.674 GFLOPs, 2.471% FLOPs, \n        (conv1): Conv2d(0.033 M, 0.037% Params, 2.097 GFLOPs, 0.675% FLOPs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.147 M, 0.168% Params, 2.359 GFLOPs, 0.760% FLOPs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.001% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.066 M, 0.075% Params, 1.049 GFLOPs, 0.338% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.001 M, 0.001% Params, 0.016 GFLOPs, 0.005% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.018 GFLOPs, 0.006% FLOPs, inplace=True)\n        (downsample): Sequential(\n          0.132 M, 0.150% Params, 2.114 GFLOPs, 0.681% FLOPs, \n          (0): Conv2d(0.131 M, 0.149% Params, 2.097 GFLOPs, 0.675% FLOPs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(0.001 M, 0.001% Params, 0.016 GFLOPs, 0.005% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        0.28 M, 0.319% Params, 4.493 GFLOPs, 1.447% FLOPs, \n        (conv1): Conv2d(0.066 M, 0.075% Params, 1.049 GFLOPs, 0.338% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.001% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.147 M, 0.168% Params, 2.359 GFLOPs, 0.760% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.001% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.066 M, 0.075% Params, 1.049 GFLOPs, 0.338% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.001 M, 0.001% Params, 0.016 GFLOPs, 0.005% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.012 GFLOPs, 0.004% FLOPs, inplace=True)\n      )\n      (2): Bottleneck(\n        0.28 M, 0.319% Params, 4.493 GFLOPs, 1.447% FLOPs, \n        (conv1): Conv2d(0.066 M, 0.075% Params, 1.049 GFLOPs, 0.338% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.001% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.147 M, 0.168% Params, 2.359 GFLOPs, 0.760% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.001% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.066 M, 0.075% Params, 1.049 GFLOPs, 0.338% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.001 M, 0.001% Params, 0.016 GFLOPs, 0.005% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.012 GFLOPs, 0.004% FLOPs, inplace=True)\n      )\n      (3): Bottleneck(\n        0.28 M, 0.319% Params, 4.493 GFLOPs, 1.447% FLOPs, \n        (conv1): Conv2d(0.066 M, 0.075% Params, 1.049 GFLOPs, 0.338% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.001% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.147 M, 0.168% Params, 2.359 GFLOPs, 0.760% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.001% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.066 M, 0.075% Params, 1.049 GFLOPs, 0.338% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.001 M, 0.001% Params, 0.016 GFLOPs, 0.005% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.012 GFLOPs, 0.004% FLOPs, inplace=True)\n      )\n    )\n    (layer3): ResLayer(\n      26.09 M, 29.676% Params, 106.085 GFLOPs, 34.162% FLOPs, \n      (0): Bottleneck(\n        1.512 M, 1.720% Params, 7.638 GFLOPs, 2.460% FLOPs, \n        (conv1): Conv2d(0.131 M, 0.149% Params, 2.097 GFLOPs, 0.675% FLOPs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.008 GFLOPs, 0.003% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.009 GFLOPs, 0.003% FLOPs, inplace=True)\n        (downsample): Sequential(\n          0.526 M, 0.599% Params, 2.105 GFLOPs, 0.678% FLOPs, \n          (0): Conv2d(0.524 M, 0.596% Params, 2.097 GFLOPs, 0.675% FLOPs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (2): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (3): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (4): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (5): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (6): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (7): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (8): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (9): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (10): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (11): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (12): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (13): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (14): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (15): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (16): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (17): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (18): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (19): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (20): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (21): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n      (22): Bottleneck(\n        1.117 M, 1.271% Params, 4.475 GFLOPs, 1.441% FLOPs, \n        (conv1): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(0.59 M, 0.671% Params, 2.359 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.002 GFLOPs, 0.001% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(0.262 M, 0.298% Params, 1.049 GFLOPs, 0.338% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.002 M, 0.002% Params, 0.008 GFLOPs, 0.003% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.002% FLOPs, inplace=True)\n      )\n    )\n    (layer4): ResLayer(\n      14.965 M, 17.021% Params, 16.551 GFLOPs, 5.330% FLOPs, \n      (0): Bottleneck(\n        6.04 M, 6.869% Params, 7.62 GFLOPs, 2.454% FLOPs, \n        (conv1): Conv2d(0.524 M, 0.596% Params, 2.097 GFLOPs, 0.675% FLOPs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.004 GFLOPs, 0.001% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(2.359 M, 2.683% Params, 2.359 GFLOPs, 0.760% FLOPs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1.049 M, 1.193% Params, 1.049 GFLOPs, 0.338% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.004 M, 0.005% Params, 0.004 GFLOPs, 0.001% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.005 GFLOPs, 0.001% FLOPs, inplace=True)\n        (downsample): Sequential(\n          2.101 M, 2.390% Params, 2.101 GFLOPs, 0.677% FLOPs, \n          (0): Conv2d(2.097 M, 2.385% Params, 2.097 GFLOPs, 0.675% FLOPs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(0.004 M, 0.005% Params, 0.004 GFLOPs, 0.001% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        4.463 M, 5.076% Params, 4.466 GFLOPs, 1.438% FLOPs, \n        (conv1): Conv2d(1.049 M, 1.193% Params, 1.049 GFLOPs, 0.338% FLOPs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(2.359 M, 2.683% Params, 2.359 GFLOPs, 0.760% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1.049 M, 1.193% Params, 1.049 GFLOPs, 0.338% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.004 M, 0.005% Params, 0.004 GFLOPs, 0.001% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.001% FLOPs, inplace=True)\n      )\n      (2): Bottleneck(\n        4.463 M, 5.076% Params, 4.466 GFLOPs, 1.438% FLOPs, \n        (conv1): Conv2d(1.049 M, 1.193% Params, 1.049 GFLOPs, 0.338% FLOPs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(2.359 M, 2.683% Params, 2.359 GFLOPs, 0.760% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(0.001 M, 0.001% Params, 0.001 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1.049 M, 1.193% Params, 1.049 GFLOPs, 0.338% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(0.004 M, 0.005% Params, 0.004 GFLOPs, 0.001% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.001% FLOPs, inplace=True)\n      )\n    )\n  )\n  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}\n  (neck): FPN(\n    3.344 M, 3.804% Params, 58.043 GFLOPs, 18.691% FLOPs, \n    (lateral_convs): ModuleList(\n      0.984 M, 1.119% Params, 7.886 GFLOPs, 2.539% FLOPs, \n      (0): ConvModule(\n        0.066 M, 0.075% Params, 4.211 GFLOPs, 1.356% FLOPs, \n        (conv): Conv2d(0.066 M, 0.075% Params, 4.211 GFLOPs, 1.356% FLOPs, 256, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): ConvModule(\n        0.131 M, 0.149% Params, 2.101 GFLOPs, 0.677% FLOPs, \n        (conv): Conv2d(0.131 M, 0.149% Params, 2.101 GFLOPs, 0.677% FLOPs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (2): ConvModule(\n        0.262 M, 0.298% Params, 1.05 GFLOPs, 0.338% FLOPs, \n        (conv): Conv2d(0.262 M, 0.298% Params, 1.05 GFLOPs, 0.338% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (3): ConvModule(\n        0.525 M, 0.597% Params, 0.525 GFLOPs, 0.169% FLOPs, \n        (conv): Conv2d(0.525 M, 0.597% Params, 0.525 GFLOPs, 0.169% FLOPs, 2048, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (fpn_convs): ModuleList(\n      2.36 M, 2.685% Params, 50.157 GFLOPs, 16.152% FLOPs, \n      (0): ConvModule(\n        0.59 M, 0.671% Params, 37.765 GFLOPs, 12.161% FLOPs, \n        (conv): Conv2d(0.59 M, 0.671% Params, 37.765 GFLOPs, 12.161% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (1): ConvModule(\n        0.59 M, 0.671% Params, 9.441 GFLOPs, 3.040% FLOPs, \n        (conv): Conv2d(0.59 M, 0.671% Params, 9.441 GFLOPs, 3.040% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (2): ConvModule(\n        0.59 M, 0.671% Params, 2.36 GFLOPs, 0.760% FLOPs, \n        (conv): Conv2d(0.59 M, 0.671% Params, 2.36 GFLOPs, 0.760% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (3): ConvModule(\n        0.59 M, 0.671% Params, 0.59 GFLOPs, 0.190% FLOPs, \n        (conv): Conv2d(0.59 M, 0.671% Params, 0.59 GFLOPs, 0.190% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n  )\n  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n  (rpn_head): RPNHead(\n    0.594 M, 0.676% Params, 50.639 GFLOPs, 16.307% FLOPs, \n    (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\n    (loss_bbox): L1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n    (rpn_conv): Conv2d(0.59 M, 0.671% Params, 50.31 GFLOPs, 16.201% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (rpn_cls): Conv2d(0.001 M, 0.001% Params, 0.066 GFLOPs, 0.021% FLOPs, 256, 3, kernel_size=(1, 1), stride=(1, 1))\n    (rpn_reg): Conv2d(0.003 M, 0.004% Params, 0.263 GFLOPs, 0.085% FLOPs, 256, 12, kernel_size=(1, 1), stride=(1, 1))\n  )\n  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n  (roi_head): CascadeRoIHead(\n    41.705 M, 47.436% Params, 41.705 GFLOPs, 13.430% FLOPs, \n    (bbox_roi_extractor): ModuleList(\n      0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n      (0): SingleRoIExtractor(\n        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n        (roi_layers): ModuleList(\n          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        )\n      )\n      (1): SingleRoIExtractor(\n        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n        (roi_layers): ModuleList(\n          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        )\n      )\n      (2): SingleRoIExtractor(\n        0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n        (roi_layers): ModuleList(\n          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        )\n      )\n    )\n    (bbox_head): ModuleList(\n      41.705 M, 47.436% Params, 41.705 GFLOPs, 13.430% FLOPs, \n      (0): Shared2FCBBoxHead(\n        13.902 M, 15.812% Params, 13.902 GFLOPs, 4.477% FLOPs, \n        (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\n        (loss_bbox): SmoothL1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (fc_cls): Linear(0.002 M, 0.002% Params, 0.002 GFLOPs, 0.001% FLOPs, in_features=1024, out_features=2, bias=True)\n        (fc_reg): Linear(0.004 M, 0.005% Params, 0.004 GFLOPs, 0.001% FLOPs, in_features=1024, out_features=4, bias=True)\n        (shared_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (shared_fcs): ModuleList(\n          13.896 M, 15.805% Params, 13.894 GFLOPs, 4.474% FLOPs, \n          (0): Linear(12.846 M, 14.611% Params, 12.845 GFLOPs, 4.136% FLOPs, in_features=12544, out_features=1024, bias=True)\n          (1): Linear(1.05 M, 1.194% Params, 1.049 GFLOPs, 0.338% FLOPs, in_features=1024, out_features=1024, bias=True)\n        )\n        (cls_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (cls_fcs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (reg_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (reg_fcs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, inplace=True)\n      )\n      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n      (1): Shared2FCBBoxHead(\n        13.902 M, 15.812% Params, 13.902 GFLOPs, 4.477% FLOPs, \n        (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\n        (loss_bbox): SmoothL1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (fc_cls): Linear(0.002 M, 0.002% Params, 0.002 GFLOPs, 0.001% FLOPs, in_features=1024, out_features=2, bias=True)\n        (fc_reg): Linear(0.004 M, 0.005% Params, 0.004 GFLOPs, 0.001% FLOPs, in_features=1024, out_features=4, bias=True)\n        (shared_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (shared_fcs): ModuleList(\n          13.896 M, 15.805% Params, 13.894 GFLOPs, 4.474% FLOPs, \n          (0): Linear(12.846 M, 14.611% Params, 12.845 GFLOPs, 4.136% FLOPs, in_features=12544, out_features=1024, bias=True)\n          (1): Linear(1.05 M, 1.194% Params, 1.049 GFLOPs, 0.338% FLOPs, in_features=1024, out_features=1024, bias=True)\n        )\n        (cls_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (cls_fcs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (reg_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (reg_fcs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, inplace=True)\n      )\n      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n      (2): Shared2FCBBoxHead(\n        13.902 M, 15.812% Params, 13.902 GFLOPs, 4.477% FLOPs, \n        (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, avg_non_ignore=False)\n        (loss_bbox): SmoothL1Loss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (fc_cls): Linear(0.002 M, 0.002% Params, 0.002 GFLOPs, 0.001% FLOPs, in_features=1024, out_features=2, bias=True)\n        (fc_reg): Linear(0.004 M, 0.005% Params, 0.004 GFLOPs, 0.001% FLOPs, in_features=1024, out_features=4, bias=True)\n        (shared_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (shared_fcs): ModuleList(\n          13.896 M, 15.805% Params, 13.894 GFLOPs, 4.474% FLOPs, \n          (0): Linear(12.846 M, 14.611% Params, 12.845 GFLOPs, 4.136% FLOPs, in_features=12544, out_features=1024, bias=True)\n          (1): Linear(1.05 M, 1.194% Params, 1.049 GFLOPs, 0.338% FLOPs, in_features=1024, out_features=1024, bias=True)\n        )\n        (cls_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (cls_fcs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (reg_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (reg_fcs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n        (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, inplace=True)\n      )\n      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n    )\n  )\n)\n==============================\nInput shape: (3, 1280, 800)\nFlops: 310.54 GFLOPs\nParams: 87.92 M\n==============================\n!!!Please be cautious if you use the results in papers. You may need to check if all ops are supported and verify that the flops computation is correct.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}